{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wave\n",
    "import soundfile as sf\n",
    "import os\n",
    "import librosa\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "import random\n",
    "from playsound import playsound\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_class = ('dog','rooster','pig','cow','frog','cat','hen','insects','sheep','crow','rain','sea_waves','crackling_fire','crickets','chirping_birds','water_drops','wind'\n",
    ",'pouring_water','toilet_flush','thunderstorm','crying_baby','sneezing','clapping','breathing','coughing','footsteps','laughing','brushing_teeth','snoring','drinking_sipping'\n",
    ",'door_wood_knock','mouse_click','keyboard_typing','door_wood_creaks','can_opening','washing_machine','vacuum_cleaner','clock_alarm','clock_tick','glass_breaking'\n",
    ",'helicopter','chainsaw','siren','car_horn','engine','train','church_bells','airplane','fireworks','hand_saw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_wav(oggfile):\n",
    "    data, samplerate = sf.read(oggfile)\n",
    "    if not os.path.exists(oggfile):\n",
    "        print('Path is not exist!')\n",
    "        return None\n",
    "    spf = wave.open(oggfile)\n",
    "    signal = spf.readframes(-1)\n",
    "    signal = np.fromstring(signal,'Int16')\n",
    "    if spf.getnchannels() == 2:\n",
    "        print('just mono files. not stereo')\n",
    "        sys.exit(0)\n",
    "    # plotting x axis in seconds. create time vector spaced linearly with size of audio file. divide size of signal by frame rate to get stop limit\n",
    "    Time = np.linspace(0,len(signal)/samplerate, num = len(signal))\n",
    "    plt.figure(1)\n",
    "    plt.title('Signal Wave Vs Time(sec)')\n",
    "    plt.plot(Time, signal)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admins\\Anaconda3\\envs\\rnn-env\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Numeric-style type codes are deprecated and will result in an error in the future.\n",
      "  \n",
      "C:\\Users\\Admins\\Anaconda3\\envs\\rnn-env\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Example of files wav\n",
    "visualize_wav('E:/Dataset/ESC-50-master/audio/1-5996-A-6.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None\n",
    "    return mfccsscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features():\n",
    "    # path to dataset containing 10 subdirectories of .ogg files\n",
    "    data_set_path = 'E:/Dataset/ESC-50-master/audio'\n",
    "    sub_dirs = os.listdir(data_set_path)  \n",
    "    features_list = []\n",
    "    for label, sub_dir in enumerate(sub_dirs):\n",
    "        file_name = str(data_set_path+'/'+sub_dir)\n",
    "        label = sub_dir\n",
    "        label = label.split('-')\n",
    "        label = label[3].split('.')\n",
    "        label = int(label[0])\n",
    "        try:\n",
    "            mfccs = get_features(file_name)\n",
    "        except Exception as e:\n",
    "            print(\"Extraction error\" , file_name)\n",
    "            continue\n",
    "        features_list.append([mfccs,label_class[label]])\n",
    "    features_df = pd.DataFrame(features_list,columns = ['feature','class_label'])\n",
    "    print(features_df.head())    \n",
    "    return features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_array(features_df):\n",
    "    X = np.array(features_df.feature.tolist())\n",
    "    y = np.array(features_df.class_label.tolist())\n",
    "    # encode classification labels\n",
    "    le = LabelEncoder()\n",
    "    yy = to_categorical(le.fit_transform(y)) \n",
    "    #le = LabelEncoder()\n",
    "    # one hot encoded labels\n",
    "    #yy = to_categorical(le.fit_transform(y))\n",
    "    return X,yy,le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 42)\n",
    "    return  X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(X_test,y_test,model_file):\n",
    "    # load model from disk\n",
    "    loaded_model = load_model(model_file)\n",
    "    score = loaded_model.evaluate(X_test,y_test)\n",
    "    return score[0],score[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(num_labels):\n",
    "    # Construct model \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(256,input_shape = (40,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(256,input_shape = (40,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(256,input_shape = (40,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(num_labels))\n",
    "    model.add(Activation('softmax'))\n",
    "    print('Model is created!')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,X_train, X_test, y_train, y_test):    \n",
    "    # compile the model \n",
    "\n",
    "    #X_train = X_train.reshape(X_train.shape[0], num_rows, num_columns, num_channels)\n",
    "    #X_test = X_test.reshape(X_test.shape[0], num_rows, num_columns, num_channels)\n",
    "    model.compile(loss = 'categorical_crossentropy',metrics=['accuracy'],optimizer='adam')\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    #print(\"training for xxx epochs with batch size 32\")\n",
    "\n",
    "    model.fit(X_train,y_train,batch_size= 64, epochs = 1000, validation_data=(X_test,y_test))\n",
    "\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model,model_file):\n",
    "    # save model to disk\n",
    "    model.save(model_file)\n",
    "    print(\"Saving model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(filename,le,model_file,label,is_play_sound = True):\n",
    "    model = model_file\n",
    "    prediction_feature = get_features(filename)\n",
    "    prediction_feature = np.array([prediction_feature])\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predicted_class = le.inverse_transform(predicted_vector)\n",
    "    print(\"Predicted class : \", predicted_class[0], label[int(predicted_class[0])])\n",
    "    predicted_proba_vector = model.predict_proba([prediction_feature])\n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "   # print(predicted_proba_vector[0].shape)\n",
    "    print(\"Probability : \", np.amax(predicted_proba)*100)\n",
    "    if is_play_sound:playsound(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predic_multiple(model,le,label,number = 10, path= 'E:/Dataset/ESC-50-master/audio', is_play_sound = True):\n",
    "        data_set_path = path\n",
    "        sub_dirs = os.listdir(data_set_path)    \n",
    "        for x in range(number):\n",
    "            sub_der = sub_dirs[randint(0, len(sub_dirs)-1)]\n",
    "            file_name = str(data_set_path+'/'+sub_der)\n",
    "            print(file_name)\n",
    "            predict(file_name,le,model,label, is_play_sound = is_play_sound)\n",
    "  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             feature     class_label\n",
      "0  [-601.34344, 5.261408, -9.065389, -3.7297597, ...             dog\n",
      "1  [-200.65897, 12.51546, -69.03366, 13.893067, -...  chirping_birds\n",
      "2  [7.54555, 69.50336, -21.42529, 27.36884, -24.8...  vacuum_cleaner\n",
      "3  [8.940394, 67.5279, -19.818014, 25.955574, -21...  vacuum_cleaner\n",
      "4  [-428.3765, 132.65819, 31.139639, 42.455814, -...    thunderstorm\n"
     ]
    }
   ],
   "source": [
    "features_df = extract_features() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.int32' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-db1ff579c86f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeatures_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.int32' object is not callable"
     ]
    }
   ],
   "source": [
    "features_df.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle and create np array for input x and u\n",
    "features_df = features_df.sample(frac=1)\n",
    "X, yy,le = get_numpy_array(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is created!\n"
     ]
    }
   ],
   "source": [
    "#create model that has 50 labels\n",
    "num_labels = 50\n",
    "model = create_mlp(num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = get_train_test(X,yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 512)               20992     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 50)                3250      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 50)                0         \n",
      "=================================================================\n",
      "Total params: 196,722\n",
      "Trainable params: 196,722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3200 samples, validate on 800 samples\n",
      "Epoch 1/800\n",
      "3200/3200 [==============================] - 2s 681us/step - loss: 15.1057 - acc: 0.0200 - val_loss: 11.3171 - val_acc: 0.0375\n",
      "Epoch 2/800\n",
      "3200/3200 [==============================] - 1s 291us/step - loss: 13.0784 - acc: 0.0213 - val_loss: 4.0569 - val_acc: 0.0238\n",
      "Epoch 3/800\n",
      "3200/3200 [==============================] - 1s 231us/step - loss: 5.9827 - acc: 0.0256 - val_loss: 3.9115 - val_acc: 0.0250\n",
      "Epoch 4/800\n",
      "3200/3200 [==============================] - 1s 217us/step - loss: 4.0633 - acc: 0.0194 - val_loss: 3.9120 - val_acc: 0.0238\n",
      "Epoch 5/800\n",
      "3200/3200 [==============================] - 1s 280us/step - loss: 3.9692 - acc: 0.0169 - val_loss: 3.9127 - val_acc: 0.0238\n",
      "Epoch 6/800\n",
      "3200/3200 [==============================] - 1s 188us/step - loss: 3.9393 - acc: 0.0109 - val_loss: 3.9134 - val_acc: 0.0238\n",
      "Epoch 7/800\n",
      "3200/3200 [==============================] - 1s 301us/step - loss: 3.9307 - acc: 0.0219 - val_loss: 3.9129 - val_acc: 0.0187\n",
      "Epoch 8/800\n",
      "3200/3200 [==============================] - 1s 323us/step - loss: 3.9198 - acc: 0.0219 - val_loss: 3.9124 - val_acc: 0.0238- loss: 3.9209 - acc: 0\n",
      "Epoch 9/800\n",
      "3200/3200 [==============================] - 1s 201us/step - loss: 3.9229 - acc: 0.0225 - val_loss: 3.9125 - val_acc: 0.0187\n",
      "Epoch 10/800\n",
      "3200/3200 [==============================] - 1s 202us/step - loss: 3.9198 - acc: 0.0222 - val_loss: 3.9122 - val_acc: 0.0213\n",
      "Epoch 11/800\n",
      "3200/3200 [==============================] - 1s 211us/step - loss: 3.9115 - acc: 0.0241 - val_loss: 3.9095 - val_acc: 0.0262\n",
      "Epoch 12/800\n",
      "3200/3200 [==============================] - 1s 218us/step - loss: 3.9114 - acc: 0.0203 - val_loss: 3.9045 - val_acc: 0.0338\n",
      "Epoch 13/800\n",
      "3200/3200 [==============================] - 1s 248us/step - loss: 3.9120 - acc: 0.0281 - val_loss: 3.8959 - val_acc: 0.0362\n",
      "Epoch 14/800\n",
      "3200/3200 [==============================] - 1s 255us/step - loss: 3.9061 - acc: 0.0300 - val_loss: 3.8944 - val_acc: 0.0350\n",
      "Epoch 15/800\n",
      "3200/3200 [==============================] - 1s 274us/step - loss: 3.9026 - acc: 0.0259 - val_loss: 3.8867 - val_acc: 0.0338\n",
      "Epoch 16/800\n",
      "3200/3200 [==============================] - 1s 201us/step - loss: 3.8940 - acc: 0.0297 - val_loss: 3.8823 - val_acc: 0.0437\n",
      "Epoch 17/800\n",
      "3200/3200 [==============================] - 1s 192us/step - loss: 3.8803 - acc: 0.0359 - val_loss: 3.8641 - val_acc: 0.0387\n",
      "Epoch 18/800\n",
      "3200/3200 [==============================] - 1s 169us/step - loss: 3.8780 - acc: 0.0344 - val_loss: 3.8549 - val_acc: 0.0437\n",
      "Epoch 19/800\n",
      "3200/3200 [==============================] - 1s 178us/step - loss: 3.8730 - acc: 0.0253 - val_loss: 3.8437 - val_acc: 0.0400\n",
      "Epoch 20/800\n",
      "3200/3200 [==============================] - 1s 175us/step - loss: 3.8677 - acc: 0.0312 - val_loss: 3.8573 - val_acc: 0.0413\n",
      "Epoch 21/800\n",
      "3200/3200 [==============================] - 1s 170us/step - loss: 3.8633 - acc: 0.0331 - val_loss: 3.8224 - val_acc: 0.0437\n",
      "Epoch 22/800\n",
      "3200/3200 [==============================] - 1s 187us/step - loss: 3.8332 - acc: 0.0387 - val_loss: 3.7662 - val_acc: 0.0500\n",
      "Epoch 23/800\n",
      "3200/3200 [==============================] - 1s 205us/step - loss: 3.8199 - acc: 0.0372 - val_loss: 3.7662 - val_acc: 0.0437\n",
      "Epoch 24/800\n",
      "3200/3200 [==============================] - 1s 220us/step - loss: 3.7920 - acc: 0.0403 - val_loss: 3.7325 - val_acc: 0.0550\n",
      "Epoch 25/800\n",
      "3200/3200 [==============================] - 1s 215us/step - loss: 3.7883 - acc: 0.0428 - val_loss: 3.6822 - val_acc: 0.0638\n",
      "Epoch 26/800\n",
      "3200/3200 [==============================] - 1s 202us/step - loss: 3.7670 - acc: 0.0434 - val_loss: 3.6800 - val_acc: 0.0587\n",
      "Epoch 27/800\n",
      "3200/3200 [==============================] - 1s 178us/step - loss: 3.7495 - acc: 0.0453 - val_loss: 3.6469 - val_acc: 0.0675\n",
      "Epoch 28/800\n",
      "3200/3200 [==============================] - 1s 186us/step - loss: 3.7422 - acc: 0.0416 - val_loss: 3.6305 - val_acc: 0.0700\n",
      "Epoch 29/800\n",
      "3200/3200 [==============================] - 1s 177us/step - loss: 3.7271 - acc: 0.0500 - val_loss: 3.6066 - val_acc: 0.0813\n",
      "Epoch 30/800\n",
      "3200/3200 [==============================] - 1s 209us/step - loss: 3.7099 - acc: 0.0506 - val_loss: 3.5823 - val_acc: 0.0825\n",
      "Epoch 31/800\n",
      "3200/3200 [==============================] - 2s 571us/step - loss: 3.6921 - acc: 0.0512 - val_loss: 3.5844 - val_acc: 0.0912\n",
      "Epoch 32/800\n",
      "3200/3200 [==============================] - 1s 311us/step - loss: 3.6767 - acc: 0.0491 - val_loss: 3.5310 - val_acc: 0.0750\n",
      "Epoch 33/800\n",
      "3200/3200 [==============================] - 1s 223us/step - loss: 3.6549 - acc: 0.0587 - val_loss: 3.5267 - val_acc: 0.0875\n",
      "Epoch 34/800\n",
      "3200/3200 [==============================] - 1s 204us/step - loss: 3.6465 - acc: 0.0591 - val_loss: 3.5375 - val_acc: 0.0675\n",
      "Epoch 35/800\n",
      "3200/3200 [==============================] - 1s 211us/step - loss: 3.6473 - acc: 0.0575 - val_loss: 3.5282 - val_acc: 0.0775\n",
      "Epoch 36/800\n",
      "3200/3200 [==============================] - 1s 178us/step - loss: 3.6142 - acc: 0.0641 - val_loss: 3.4822 - val_acc: 0.0813\n",
      "Epoch 37/800\n",
      "3200/3200 [==============================] - 1s 189us/step - loss: 3.6244 - acc: 0.0603 - val_loss: 3.4916 - val_acc: 0.0725\n",
      "Epoch 38/800\n",
      "3200/3200 [==============================] - 1s 201us/step - loss: 3.6109 - acc: 0.0619 - val_loss: 3.4713 - val_acc: 0.0737\n",
      "Epoch 39/800\n",
      "3200/3200 [==============================] - 1s 247us/step - loss: 3.5810 - acc: 0.0625 - val_loss: 3.4355 - val_acc: 0.0838\n",
      "Epoch 40/800\n",
      "3200/3200 [==============================] - 2s 487us/step - loss: 3.5818 - acc: 0.0581 - val_loss: 3.4662 - val_acc: 0.0813\n",
      "Epoch 41/800\n",
      "3200/3200 [==============================] - 1s 337us/step - loss: 3.5649 - acc: 0.0606 - val_loss: 3.4337 - val_acc: 0.0887\n",
      "Epoch 42/800\n",
      "3200/3200 [==============================] - 1s 188us/step - loss: 3.5684 - acc: 0.0603 - val_loss: 3.4467 - val_acc: 0.0788\n",
      "Epoch 43/800\n",
      "3200/3200 [==============================] - 1s 212us/step - loss: 3.5679 - acc: 0.0641 - val_loss: 3.4153 - val_acc: 0.0850\n",
      "Epoch 44/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3200 [==============================] - 1s 179us/step - loss: 3.5294 - acc: 0.0691 - val_loss: 3.3895 - val_acc: 0.0938\n",
      "Epoch 45/800\n",
      "3200/3200 [==============================] - 1s 160us/step - loss: 3.5225 - acc: 0.0688 - val_loss: 3.3838 - val_acc: 0.0938\n",
      "Epoch 46/800\n",
      "3200/3200 [==============================] - 1s 165us/step - loss: 3.5122 - acc: 0.0663 - val_loss: 3.3487 - val_acc: 0.0963\n",
      "Epoch 47/800\n",
      "3200/3200 [==============================] - 1s 168us/step - loss: 3.4912 - acc: 0.0700 - val_loss: 3.3804 - val_acc: 0.1037\n",
      "Epoch 48/800\n",
      "3200/3200 [==============================] - 1s 164us/step - loss: 3.4670 - acc: 0.0778 - val_loss: 3.3541 - val_acc: 0.1150\n",
      "Epoch 49/800\n",
      "3200/3200 [==============================] - 1s 168us/step - loss: 3.4686 - acc: 0.0797 - val_loss: 3.3533 - val_acc: 0.1087\n",
      "Epoch 50/800\n",
      "3200/3200 [==============================] - 1s 163us/step - loss: 3.4479 - acc: 0.0841 - val_loss: 3.3230 - val_acc: 0.1013\n",
      "Epoch 51/800\n",
      "3200/3200 [==============================] - 1s 172us/step - loss: 3.4469 - acc: 0.0822 - val_loss: 3.3341 - val_acc: 0.1013\n",
      "Epoch 52/800\n",
      "3200/3200 [==============================] - 1s 202us/step - loss: 3.4397 - acc: 0.0844 - val_loss: 3.3105 - val_acc: 0.1263\n",
      "Epoch 53/800\n",
      "3200/3200 [==============================] - 1s 212us/step - loss: 3.4225 - acc: 0.0784 - val_loss: 3.3020 - val_acc: 0.1212\n",
      "Epoch 54/800\n",
      "3200/3200 [==============================] - 1s 194us/step - loss: 3.3867 - acc: 0.0897 - val_loss: 3.2549 - val_acc: 0.1313\n",
      "Epoch 55/800\n",
      "3200/3200 [==============================] - 1s 160us/step - loss: 3.4034 - acc: 0.0891 - val_loss: 3.2741 - val_acc: 0.1263\n",
      "Epoch 56/800\n",
      "3200/3200 [==============================] - 1s 159us/step - loss: 3.3888 - acc: 0.0916 - val_loss: 3.2713 - val_acc: 0.1425\n",
      "Epoch 57/800\n",
      "3200/3200 [==============================] - 1s 158us/step - loss: 3.3538 - acc: 0.0972 - val_loss: 3.2403 - val_acc: 0.1338\n",
      "Epoch 58/800\n",
      "3200/3200 [==============================] - 1s 165us/step - loss: 3.3384 - acc: 0.0919 - val_loss: 3.2364 - val_acc: 0.1400\n",
      "Epoch 59/800\n",
      "3200/3200 [==============================] - 1s 204us/step - loss: 3.3168 - acc: 0.0991 - val_loss: 3.2172 - val_acc: 0.1325\n",
      "Epoch 60/800\n",
      "3200/3200 [==============================] - 1s 164us/step - loss: 3.3532 - acc: 0.0950 - val_loss: 3.2500 - val_acc: 0.1263\n",
      "Epoch 61/800\n",
      "3200/3200 [==============================] - 1s 182us/step - loss: 3.3283 - acc: 0.1050 - val_loss: 3.2039 - val_acc: 0.1163\n",
      "Epoch 62/800\n",
      "3200/3200 [==============================] - 1s 191us/step - loss: 3.3212 - acc: 0.0969 - val_loss: 3.1810 - val_acc: 0.1400\n",
      "Epoch 63/800\n",
      "3200/3200 [==============================] - 1s 171us/step - loss: 3.2821 - acc: 0.1159 - val_loss: 3.1898 - val_acc: 0.1462\n",
      "Epoch 64/800\n",
      "3200/3200 [==============================] - 1s 174us/step - loss: 3.2735 - acc: 0.1094 - val_loss: 3.1751 - val_acc: 0.1375\n",
      "Epoch 65/800\n",
      "3200/3200 [==============================] - 1s 209us/step - loss: 3.2797 - acc: 0.1100 - val_loss: 3.1508 - val_acc: 0.1338\n",
      "Epoch 66/800\n",
      "3200/3200 [==============================] - 1s 202us/step - loss: 3.2651 - acc: 0.1069 - val_loss: 3.1512 - val_acc: 0.1313\n",
      "Epoch 67/800\n",
      "3200/3200 [==============================] - 1s 345us/step - loss: 3.2428 - acc: 0.1231 - val_loss: 3.1176 - val_acc: 0.1400\n",
      "Epoch 68/800\n",
      "3200/3200 [==============================] - 1s 384us/step - loss: 3.2515 - acc: 0.1106 - val_loss: 3.1199 - val_acc: 0.1375\n",
      "Epoch 69/800\n",
      "3200/3200 [==============================] - 1s 212us/step - loss: 3.2307 - acc: 0.1134 - val_loss: 3.1219 - val_acc: 0.1412\n",
      "Epoch 70/800\n",
      "3200/3200 [==============================] - 1s 185us/step - loss: 3.2120 - acc: 0.1266 - val_loss: 3.1193 - val_acc: 0.1487\n",
      "Epoch 71/800\n",
      "3200/3200 [==============================] - 1s 206us/step - loss: 3.2345 - acc: 0.1066 - val_loss: 3.0727 - val_acc: 0.1562\n",
      "Epoch 72/800\n",
      "3200/3200 [==============================] - 1s 375us/step - loss: 3.1838 - acc: 0.1184 - val_loss: 3.0580 - val_acc: 0.1825\n",
      "Epoch 73/800\n",
      "3200/3200 [==============================] - 1s 360us/step - loss: 3.1687 - acc: 0.1269 - val_loss: 3.0219 - val_acc: 0.1812\n",
      "Epoch 74/800\n",
      "3200/3200 [==============================] - 1s 212us/step - loss: 3.1713 - acc: 0.1256 - val_loss: 3.0067 - val_acc: 0.1700\n",
      "Epoch 75/800\n",
      "3200/3200 [==============================] - 1s 285us/step - loss: 3.1524 - acc: 0.1288 - val_loss: 2.9866 - val_acc: 0.1725\n",
      "Epoch 76/800\n",
      "3200/3200 [==============================] - 1s 222us/step - loss: 3.1322 - acc: 0.1406 - val_loss: 3.0054 - val_acc: 0.1625\n",
      "Epoch 77/800\n",
      "3200/3200 [==============================] - 1s 196us/step - loss: 3.1300 - acc: 0.1247 - val_loss: 2.9821 - val_acc: 0.1713\n",
      "Epoch 78/800\n",
      "3200/3200 [==============================] - 1s 187us/step - loss: 3.1104 - acc: 0.1375 - val_loss: 2.9400 - val_acc: 0.1925\n",
      "Epoch 79/800\n",
      "3200/3200 [==============================] - 1s 209us/step - loss: 3.0869 - acc: 0.1338 - val_loss: 2.9827 - val_acc: 0.1950\n",
      "Epoch 80/800\n",
      "3200/3200 [==============================] - 1s 212us/step - loss: 3.0789 - acc: 0.1350 - val_loss: 2.9420 - val_acc: 0.1850\n",
      "Epoch 81/800\n",
      "3200/3200 [==============================] - 1s 198us/step - loss: 3.0881 - acc: 0.1391 - val_loss: 2.9117 - val_acc: 0.1713\n",
      "Epoch 82/800\n",
      "3200/3200 [==============================] - 1s 175us/step - loss: 3.0697 - acc: 0.1409 - val_loss: 2.9264 - val_acc: 0.1925\n",
      "Epoch 83/800\n",
      "3200/3200 [==============================] - 1s 200us/step - loss: 3.0511 - acc: 0.1547 - val_loss: 2.8722 - val_acc: 0.2150\n",
      "Epoch 84/800\n",
      "3200/3200 [==============================] - 1s 204us/step - loss: 3.0386 - acc: 0.1503 - val_loss: 2.8864 - val_acc: 0.2087\n",
      "Epoch 85/800\n",
      "3200/3200 [==============================] - 1s 183us/step - loss: 3.0229 - acc: 0.1606 - val_loss: 2.8521 - val_acc: 0.2087\n",
      "Epoch 86/800\n",
      "3200/3200 [==============================] - 1s 177us/step - loss: 3.0116 - acc: 0.1650 - val_loss: 2.8136 - val_acc: 0.2062\n",
      "Epoch 87/800\n",
      "3200/3200 [==============================] - 1s 199us/step - loss: 2.9644 - acc: 0.1666 - val_loss: 2.8205 - val_acc: 0.2112\n",
      "Epoch 88/800\n",
      "3200/3200 [==============================] - 1s 220us/step - loss: 2.9607 - acc: 0.1681 - val_loss: 2.8069 - val_acc: 0.2162\n",
      "Epoch 89/800\n",
      "3200/3200 [==============================] - 1s 210us/step - loss: 2.9359 - acc: 0.1837 - val_loss: 2.8111 - val_acc: 0.2213\n",
      "Epoch 90/800\n",
      "3200/3200 [==============================] - 1s 210us/step - loss: 2.9976 - acc: 0.1737 - val_loss: 2.8173 - val_acc: 0.2387\n",
      "Epoch 91/800\n",
      "3200/3200 [==============================] - 1s 196us/step - loss: 2.8932 - acc: 0.1744 - val_loss: 2.7881 - val_acc: 0.2300\n",
      "Epoch 92/800\n",
      "3200/3200 [==============================] - 1s 186us/step - loss: 2.8998 - acc: 0.1894 - val_loss: 2.7594 - val_acc: 0.2487\n",
      "Epoch 93/800\n",
      "3200/3200 [==============================] - ETA: 0s - loss: 2.9038 - acc: 0.171 - 1s 199us/step - loss: 2.9022 - acc: 0.1722 - val_loss: 2.7210 - val_acc: 0.2450\n",
      "Epoch 94/800\n",
      "3200/3200 [==============================] - 1s 184us/step - loss: 2.9002 - acc: 0.1941 - val_loss: 2.7546 - val_acc: 0.2188\n",
      "Epoch 95/800\n",
      "3200/3200 [==============================] - 1s 184us/step - loss: 2.8851 - acc: 0.1897 - val_loss: 2.7125 - val_acc: 0.2437\n",
      "Epoch 96/800\n",
      "3200/3200 [==============================] - 1s 179us/step - loss: 2.9006 - acc: 0.1956 - val_loss: 2.7724 - val_acc: 0.2562\n",
      "Epoch 97/800\n",
      "3200/3200 [==============================] - 1s 186us/step - loss: 2.8752 - acc: 0.1909 - val_loss: 2.6782 - val_acc: 0.2637\n",
      "Epoch 98/800\n",
      "3200/3200 [==============================] - 1s 173us/step - loss: 2.8412 - acc: 0.1997 - val_loss: 2.6325 - val_acc: 0.2762\n",
      "Epoch 99/800\n",
      "3200/3200 [==============================] - 1s 179us/step - loss: 2.8391 - acc: 0.1984 - val_loss: 2.6759 - val_acc: 0.2750\n",
      "Epoch 100/800\n",
      "3200/3200 [==============================] - 1s 224us/step - loss: 2.8469 - acc: 0.1944 - val_loss: 2.6632 - val_acc: 0.2737\n",
      "Epoch 101/800\n",
      "3200/3200 [==============================] - 1s 233us/step - loss: 2.8039 - acc: 0.1994 - val_loss: 2.6235 - val_acc: 0.2938\n",
      "Epoch 102/800\n",
      "3200/3200 [==============================] - 1s 182us/step - loss: 2.7899 - acc: 0.2059 - val_loss: 2.5908 - val_acc: 0.2875\n",
      "Epoch 103/800\n",
      "3200/3200 [==============================] - 1s 174us/step - loss: 2.7666 - acc: 0.2100 - val_loss: 2.5741 - val_acc: 0.2863\n",
      "Epoch 104/800\n",
      "3200/3200 [==============================] - 1s 175us/step - loss: 2.8042 - acc: 0.2053 - val_loss: 2.5752 - val_acc: 0.2950\n",
      "Epoch 105/800\n",
      "3200/3200 [==============================] - 1s 158us/step - loss: 2.7728 - acc: 0.2162 - val_loss: 2.5972 - val_acc: 0.3025\n",
      "Epoch 106/800\n",
      "3200/3200 [==============================] - 1s 161us/step - loss: 2.7437 - acc: 0.2216 - val_loss: 2.5220 - val_acc: 0.2963\n",
      "Epoch 107/800\n",
      "3200/3200 [==============================] - 0s 156us/step - loss: 2.7516 - acc: 0.2175 - val_loss: 2.5420 - val_acc: 0.3125\n",
      "Epoch 108/800\n",
      "3200/3200 [==============================] - 0s 156us/step - loss: 2.7139 - acc: 0.2222 - val_loss: 2.5141 - val_acc: 0.3237\n",
      "Epoch 109/800\n",
      "3200/3200 [==============================] - 0s 154us/step - loss: 2.6883 - acc: 0.2281 - val_loss: 2.4777 - val_acc: 0.3400\n",
      "Epoch 110/800\n",
      "3200/3200 [==============================] - 1s 166us/step - loss: 2.7227 - acc: 0.2281 - val_loss: 2.5284 - val_acc: 0.2988\n",
      "Epoch 111/800\n",
      "3200/3200 [==============================] - 1s 159us/step - loss: 2.6833 - acc: 0.2247 - val_loss: 2.4867 - val_acc: 0.3200\n",
      "Epoch 112/800\n",
      "3200/3200 [==============================] - 1s 168us/step - loss: 2.6484 - acc: 0.2503 - val_loss: 2.4911 - val_acc: 0.3113\n",
      "Epoch 113/800\n",
      "3200/3200 [==============================] - 1s 160us/step - loss: 2.6427 - acc: 0.2316 - val_loss: 2.4651 - val_acc: 0.3175\n",
      "Epoch 114/800\n",
      "3200/3200 [==============================] - 1s 167us/step - loss: 2.6582 - acc: 0.2497 - val_loss: 2.4473 - val_acc: 0.3312\n",
      "Epoch 115/800\n",
      "3200/3200 [==============================] - 1s 166us/step - loss: 2.6602 - acc: 0.2469 - val_loss: 2.4759 - val_acc: 0.3050\n",
      "Epoch 116/800\n",
      "3200/3200 [==============================] - 1s 159us/step - loss: 2.6261 - acc: 0.2347 - val_loss: 2.4101 - val_acc: 0.3400\n",
      "Epoch 117/800\n",
      "3200/3200 [==============================] - 1s 164us/step - loss: 2.6165 - acc: 0.2550 - val_loss: 2.4048 - val_acc: 0.3337\n",
      "Epoch 118/800\n",
      "3200/3200 [==============================] - 1s 165us/step - loss: 2.5812 - acc: 0.2584 - val_loss: 2.4048 - val_acc: 0.3450\n",
      "Epoch 119/800\n",
      "3200/3200 [==============================] - 1s 164us/step - loss: 2.5966 - acc: 0.2450 - val_loss: 2.4112 - val_acc: 0.3212\n",
      "Epoch 120/800\n",
      "3200/3200 [==============================] - 1s 165us/step - loss: 2.5767 - acc: 0.2641 - val_loss: 2.3869 - val_acc: 0.3275\n",
      "Epoch 121/800\n",
      "3200/3200 [==============================] - 1s 162us/step - loss: 2.5813 - acc: 0.2541 - val_loss: 2.3673 - val_acc: 0.3337\n",
      "Epoch 122/800\n",
      "3200/3200 [==============================] - 1s 162us/step - loss: 2.5467 - acc: 0.2694 - val_loss: 2.3707 - val_acc: 0.3287\n",
      "Epoch 123/800\n",
      "3200/3200 [==============================] - 1s 172us/step - loss: 2.5195 - acc: 0.2659 - val_loss: 2.3189 - val_acc: 0.3463\n",
      "Epoch 124/800\n",
      "3200/3200 [==============================] - 1s 164us/step - loss: 2.5541 - acc: 0.2637 - val_loss: 2.3526 - val_acc: 0.3287\n",
      "Epoch 125/800\n",
      "3200/3200 [==============================] - 1s 170us/step - loss: 2.4634 - acc: 0.2787 - val_loss: 2.2937 - val_acc: 0.3600\n",
      "Epoch 126/800\n",
      "3200/3200 [==============================] - 1s 166us/step - loss: 2.5477 - acc: 0.2694 - val_loss: 2.3404 - val_acc: 0.3350\n",
      "Epoch 127/800\n",
      "3200/3200 [==============================] - 1s 173us/step - loss: 2.5004 - acc: 0.2772 - val_loss: 2.2890 - val_acc: 0.3575\n",
      "Epoch 128/800\n",
      "3200/3200 [==============================] - 1s 168us/step - loss: 2.4957 - acc: 0.2725 - val_loss: 2.2659 - val_acc: 0.3825\n",
      "Epoch 129/800\n",
      "3200/3200 [==============================] - 1s 176us/step - loss: 2.4698 - acc: 0.2809 - val_loss: 2.3175 - val_acc: 0.3162\n",
      "Epoch 130/800\n",
      "3200/3200 [==============================] - 1s 246us/step - loss: 2.5017 - acc: 0.2728 - val_loss: 2.2507 - val_acc: 0.3600\n",
      "Epoch 131/800\n",
      "3200/3200 [==============================] - 1s 220us/step - loss: 2.4741 - acc: 0.2822 - val_loss: 2.2589 - val_acc: 0.3638\n",
      "Epoch 132/800\n",
      "3200/3200 [==============================] - 1s 193us/step - loss: 2.4770 - acc: 0.2756 - val_loss: 2.2671 - val_acc: 0.3475\n",
      "Epoch 133/800\n",
      "3200/3200 [==============================] - 1s 172us/step - loss: 2.4676 - acc: 0.2834 - val_loss: 2.2446 - val_acc: 0.3563\n",
      "Epoch 134/800\n",
      "3200/3200 [==============================] - 1s 169us/step - loss: 2.4381 - acc: 0.2800 - val_loss: 2.2367 - val_acc: 0.3500\n",
      "Epoch 135/800\n",
      "3200/3200 [==============================] - 1s 169us/step - loss: 2.4463 - acc: 0.2838 - val_loss: 2.2316 - val_acc: 0.3713\n",
      "Epoch 136/800\n",
      "3200/3200 [==============================] - 1s 172us/step - loss: 2.4329 - acc: 0.2978 - val_loss: 2.2178 - val_acc: 0.3700\n",
      "Epoch 137/800\n",
      "3200/3200 [==============================] - 1s 174us/step - loss: 2.3968 - acc: 0.2894 - val_loss: 2.1964 - val_acc: 0.3663\n",
      "Epoch 138/800\n",
      "3200/3200 [==============================] - 1s 174us/step - loss: 2.3851 - acc: 0.2969 - val_loss: 2.1652 - val_acc: 0.3862\n",
      "Epoch 139/800\n",
      "3200/3200 [==============================] - 1s 167us/step - loss: 2.3995 - acc: 0.2922 - val_loss: 2.1815 - val_acc: 0.3800\n",
      "Epoch 140/800\n",
      "3200/3200 [==============================] - 1s 167us/step - loss: 2.3841 - acc: 0.2919 - val_loss: 2.1682 - val_acc: 0.3563\n",
      "Epoch 141/800\n",
      "3200/3200 [==============================] - 1s 171us/step - loss: 2.3440 - acc: 0.3019 - val_loss: 2.1562 - val_acc: 0.3725\n",
      "Epoch 142/800\n",
      "3200/3200 [==============================] - 1s 167us/step - loss: 2.3843 - acc: 0.2994 - val_loss: 2.1551 - val_acc: 0.3800\n",
      "Epoch 143/800\n",
      "3200/3200 [==============================] - 1s 176us/step - loss: 2.3778 - acc: 0.2997 - val_loss: 2.1453 - val_acc: 0.3812\n",
      "Epoch 144/800\n",
      "3200/3200 [==============================] - 1s 197us/step - loss: 2.3957 - acc: 0.3009 - val_loss: 2.1260 - val_acc: 0.3975\n",
      "Epoch 145/800\n",
      "3200/3200 [==============================] - 1s 172us/step - loss: 2.3625 - acc: 0.3022 - val_loss: 2.1459 - val_acc: 0.3663\n",
      "Epoch 146/800\n",
      "3200/3200 [==============================] - 1s 178us/step - loss: 2.3787 - acc: 0.2975 - val_loss: 2.1434 - val_acc: 0.3912\n",
      "Epoch 147/800\n",
      "3200/3200 [==============================] - 1s 180us/step - loss: 2.2942 - acc: 0.3122 - val_loss: 2.0975 - val_acc: 0.3937\n",
      "Epoch 148/800\n",
      "3200/3200 [==============================] - 1s 218us/step - loss: 2.3283 - acc: 0.3016 - val_loss: 2.1248 - val_acc: 0.3900\n",
      "Epoch 149/800\n",
      "3200/3200 [==============================] - 1s 197us/step - loss: 2.3081 - acc: 0.3172 - val_loss: 2.0750 - val_acc: 0.3950\n",
      "Epoch 150/800\n",
      "3200/3200 [==============================] - 1s 200us/step - loss: 2.3417 - acc: 0.3153 - val_loss: 2.0880 - val_acc: 0.3950\n",
      "Epoch 151/800\n",
      "3200/3200 [==============================] - 1s 234us/step - loss: 2.2961 - acc: 0.3191 - val_loss: 2.0837 - val_acc: 0.4037\n",
      "Epoch 152/800\n",
      "3200/3200 [==============================] - 1s 197us/step - loss: 2.3163 - acc: 0.3206 - val_loss: 2.0765 - val_acc: 0.3912\n",
      "Epoch 153/800\n",
      "3200/3200 [==============================] - 1s 223us/step - loss: 2.2781 - acc: 0.3359 - val_loss: 2.0500 - val_acc: 0.4150\n",
      "Epoch 154/800\n",
      "3200/3200 [==============================] - 1s 389us/step - loss: 2.2761 - acc: 0.3222 - val_loss: 2.0225 - val_acc: 0.4062\n",
      "Epoch 155/800\n",
      "3200/3200 [==============================] - 2s 612us/step - loss: 2.2820 - acc: 0.3216 - val_loss: 2.0568 - val_acc: 0.3775\n",
      "Epoch 156/800\n",
      "3200/3200 [==============================] - 1s 301us/step - loss: 2.2725 - acc: 0.3159 - val_loss: 2.0091 - val_acc: 0.4250\n",
      "Epoch 157/800\n",
      "3200/3200 [==============================] - 1s 196us/step - loss: 2.2471 - acc: 0.3278 - val_loss: 2.0412 - val_acc: 0.4012\n",
      "Epoch 158/800\n",
      "3200/3200 [==============================] - 1s 194us/step - loss: 2.2622 - acc: 0.3253 - val_loss: 2.0445 - val_acc: 0.3987\n",
      "Epoch 159/800\n",
      "3200/3200 [==============================] - 1s 195us/step - loss: 2.2665 - acc: 0.3275 - val_loss: 1.9877 - val_acc: 0.4300\n",
      "Epoch 160/800\n",
      "3200/3200 [==============================] - 1s 205us/step - loss: 2.2123 - acc: 0.3481 - val_loss: 2.0257 - val_acc: 0.3950\n",
      "Epoch 161/800\n",
      "3200/3200 [==============================] - 1s 247us/step - loss: 2.2345 - acc: 0.3366 - val_loss: 1.9899 - val_acc: 0.4150\n",
      "Epoch 162/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3200 [==============================] - 1s 189us/step - loss: 2.2343 - acc: 0.3344 - val_loss: 1.9691 - val_acc: 0.4412\n",
      "Epoch 163/800\n",
      "3200/3200 [==============================] - 1s 214us/step - loss: 2.2224 - acc: 0.3500 - val_loss: 1.9902 - val_acc: 0.4075\n",
      "Epoch 164/800\n",
      "3200/3200 [==============================] - 1s 173us/step - loss: 2.1887 - acc: 0.3491 - val_loss: 1.9907 - val_acc: 0.4338\n",
      "Epoch 165/800\n",
      "3200/3200 [==============================] - 1s 201us/step - loss: 2.2206 - acc: 0.3497 - val_loss: 1.9549 - val_acc: 0.4475\n",
      "Epoch 166/800\n",
      "3200/3200 [==============================] - 1s 229us/step - loss: 2.2455 - acc: 0.3419 - val_loss: 2.0215 - val_acc: 0.3787\n",
      "Epoch 167/800\n",
      "3200/3200 [==============================] - 1s 195us/step - loss: 2.2518 - acc: 0.3381 - val_loss: 1.9959 - val_acc: 0.4138\n",
      "Epoch 168/800\n",
      "3200/3200 [==============================] - 1s 180us/step - loss: 2.1848 - acc: 0.3538 - val_loss: 1.9463 - val_acc: 0.4450\n",
      "Epoch 169/800\n",
      "3200/3200 [==============================] - 1s 186us/step - loss: 2.2105 - acc: 0.3522 - val_loss: 1.9686 - val_acc: 0.4300\n",
      "Epoch 170/800\n",
      "3200/3200 [==============================] - 1s 172us/step - loss: 2.1971 - acc: 0.3522 - val_loss: 1.9513 - val_acc: 0.4250\n",
      "Epoch 171/800\n",
      "3200/3200 [==============================] - 1s 190us/step - loss: 2.1925 - acc: 0.3619 - val_loss: 1.9433 - val_acc: 0.4400\n",
      "Epoch 172/800\n",
      "3200/3200 [==============================] - 1s 174us/step - loss: 2.1435 - acc: 0.3612 - val_loss: 1.9498 - val_acc: 0.4213\n",
      "Epoch 173/800\n",
      "3200/3200 [==============================] - 1s 215us/step - loss: 2.1889 - acc: 0.3466 - val_loss: 1.9756 - val_acc: 0.4350\n",
      "Epoch 174/800\n",
      "3200/3200 [==============================] - 1s 172us/step - loss: 2.1789 - acc: 0.3550 - val_loss: 1.9588 - val_acc: 0.4363\n",
      "Epoch 175/800\n",
      "3200/3200 [==============================] - 1s 182us/step - loss: 2.1433 - acc: 0.3684 - val_loss: 1.8990 - val_acc: 0.4525\n",
      "Epoch 176/800\n",
      "3200/3200 [==============================] - 1s 185us/step - loss: 2.1419 - acc: 0.3756 - val_loss: 1.9135 - val_acc: 0.4238\n",
      "Epoch 177/800\n",
      "3200/3200 [==============================] - 1s 192us/step - loss: 2.1624 - acc: 0.3519 - val_loss: 1.9584 - val_acc: 0.4263\n",
      "Epoch 178/800\n",
      "3200/3200 [==============================] - 1s 222us/step - loss: 2.2004 - acc: 0.3600 - val_loss: 1.9099 - val_acc: 0.4475\n",
      "Epoch 179/800\n",
      "3200/3200 [==============================] - 1s 239us/step - loss: 2.1748 - acc: 0.3494 - val_loss: 1.8956 - val_acc: 0.4412\n",
      "Epoch 180/800\n",
      "3200/3200 [==============================] - 1s 199us/step - loss: 2.1356 - acc: 0.3738 - val_loss: 1.8631 - val_acc: 0.4562\n",
      "Epoch 181/800\n",
      "3200/3200 [==============================] - 1s 185us/step - loss: 2.1057 - acc: 0.3687 - val_loss: 1.8680 - val_acc: 0.4450\n",
      "Epoch 182/800\n",
      "3200/3200 [==============================] - 1s 190us/step - loss: 2.1285 - acc: 0.3781 - val_loss: 1.8837 - val_acc: 0.4587\n",
      "Epoch 183/800\n",
      "3200/3200 [==============================] - 1s 201us/step - loss: 2.1319 - acc: 0.3472 - val_loss: 1.8867 - val_acc: 0.4487\n",
      "Epoch 184/800\n",
      "3200/3200 [==============================] - 1s 171us/step - loss: 2.0606 - acc: 0.3806 - val_loss: 1.8392 - val_acc: 0.4788\n",
      "Epoch 185/800\n",
      "3200/3200 [==============================] - 1s 175us/step - loss: 2.1062 - acc: 0.3669 - val_loss: 1.8270 - val_acc: 0.4713\n",
      "Epoch 186/800\n",
      "3200/3200 [==============================] - 1s 188us/step - loss: 2.0799 - acc: 0.3791 - val_loss: 1.8542 - val_acc: 0.4637\n",
      "Epoch 187/800\n",
      "3200/3200 [==============================] - 1s 172us/step - loss: 2.0498 - acc: 0.4019 - val_loss: 1.8196 - val_acc: 0.4800\n",
      "Epoch 188/800\n",
      "3200/3200 [==============================] - 1s 194us/step - loss: 2.0962 - acc: 0.3809 - val_loss: 1.8158 - val_acc: 0.4788\n",
      "Epoch 189/800\n",
      "3200/3200 [==============================] - 1s 167us/step - loss: 2.1095 - acc: 0.3700 - val_loss: 1.8389 - val_acc: 0.4713\n",
      "Epoch 190/800\n",
      "3200/3200 [==============================] - 1s 182us/step - loss: 2.0891 - acc: 0.3809 - val_loss: 1.8334 - val_acc: 0.4713\n",
      "Epoch 191/800\n",
      "3200/3200 [==============================] - 1s 170us/step - loss: 2.0627 - acc: 0.3813 - val_loss: 1.8124 - val_acc: 0.4713\n",
      "Epoch 192/800\n",
      "3200/3200 [==============================] - 1s 178us/step - loss: 2.0384 - acc: 0.3878 - val_loss: 1.8116 - val_acc: 0.4700\n",
      "Epoch 193/800\n",
      "3200/3200 [==============================] - 1s 166us/step - loss: 2.0656 - acc: 0.3919 - val_loss: 1.7968 - val_acc: 0.4850\n",
      "Epoch 194/800\n",
      "3200/3200 [==============================] - 1s 166us/step - loss: 2.0636 - acc: 0.3847 - val_loss: 1.8183 - val_acc: 0.4625\n",
      "Epoch 195/800\n",
      "3200/3200 [==============================] - 1s 186us/step - loss: 2.0861 - acc: 0.3875 - val_loss: 1.8282 - val_acc: 0.4888\n",
      "Epoch 196/800\n",
      "3200/3200 [==============================] - 1s 177us/step - loss: 2.0781 - acc: 0.3875 - val_loss: 1.8626 - val_acc: 0.4450\n",
      "Epoch 197/800\n",
      "3200/3200 [==============================] - 1s 175us/step - loss: 2.0657 - acc: 0.3897 - val_loss: 1.8488 - val_acc: 0.4688\n",
      "Epoch 198/800\n",
      "3200/3200 [==============================] - 1s 170us/step - loss: 2.0354 - acc: 0.3966 - val_loss: 1.8197 - val_acc: 0.4975\n",
      "Epoch 199/800\n",
      "3200/3200 [==============================] - 1s 176us/step - loss: 2.0779 - acc: 0.3866 - val_loss: 1.8273 - val_acc: 0.4750\n",
      "Epoch 200/800\n",
      "3200/3200 [==============================] - 1s 168us/step - loss: 2.0503 - acc: 0.3969 - val_loss: 1.8184 - val_acc: 0.4600\n",
      "Epoch 201/800\n",
      "3200/3200 [==============================] - 1s 178us/step - loss: 2.0410 - acc: 0.3928 - val_loss: 1.7607 - val_acc: 0.5075\n",
      "Epoch 202/800\n",
      "3200/3200 [==============================] - 1s 179us/step - loss: 1.9980 - acc: 0.4034 - val_loss: 1.7846 - val_acc: 0.4963\n",
      "Epoch 203/800\n",
      "3200/3200 [==============================] - 1s 171us/step - loss: 2.0475 - acc: 0.3906 - val_loss: 1.7888 - val_acc: 0.4888\n",
      "Epoch 204/800\n",
      "3200/3200 [==============================] - 1s 182us/step - loss: 1.9902 - acc: 0.4062 - val_loss: 1.7614 - val_acc: 0.5062\n",
      "Epoch 205/800\n",
      "3200/3200 [==============================] - 1s 210us/step - loss: 2.0584 - acc: 0.3916 - val_loss: 1.8257 - val_acc: 0.4587\n",
      "Epoch 206/800\n",
      "3200/3200 [==============================] - 1s 297us/step - loss: 2.0010 - acc: 0.3934 - val_loss: 1.7734 - val_acc: 0.4850\n",
      "Epoch 207/800\n",
      "3200/3200 [==============================] - 1s 210us/step - loss: 1.9954 - acc: 0.4003 - val_loss: 1.7522 - val_acc: 0.4950\n",
      "Epoch 208/800\n",
      "3200/3200 [==============================] - 1s 216us/step - loss: 1.9966 - acc: 0.4103 - val_loss: 1.7713 - val_acc: 0.4813\n",
      "Epoch 209/800\n",
      "3200/3200 [==============================] - 1s 221us/step - loss: 2.0190 - acc: 0.4081 - val_loss: 1.7753 - val_acc: 0.4875\n",
      "Epoch 210/800\n",
      "3200/3200 [==============================] - 1s 182us/step - loss: 1.9848 - acc: 0.4147 - val_loss: 1.7450 - val_acc: 0.5212\n",
      "Epoch 211/800\n",
      "3200/3200 [==============================] - 1s 174us/step - loss: 2.0134 - acc: 0.4034 - val_loss: 1.7636 - val_acc: 0.5075\n",
      "Epoch 212/800\n",
      "3200/3200 [==============================] - 1s 186us/step - loss: 2.0111 - acc: 0.4122 - val_loss: 1.7658 - val_acc: 0.5225\n",
      "Epoch 213/800\n",
      "3200/3200 [==============================] - 1s 194us/step - loss: 1.9770 - acc: 0.4147 - val_loss: 1.7130 - val_acc: 0.5437\n",
      "Epoch 214/800\n",
      "3200/3200 [==============================] - 1s 171us/step - loss: 1.9338 - acc: 0.4278 - val_loss: 1.7437 - val_acc: 0.4875\n",
      "Epoch 215/800\n",
      "3200/3200 [==============================] - 1s 172us/step - loss: 1.9622 - acc: 0.4109 - val_loss: 1.7377 - val_acc: 0.5062\n",
      "Epoch 216/800\n",
      "3200/3200 [==============================] - 1s 178us/step - loss: 1.9774 - acc: 0.4178 - val_loss: 1.7276 - val_acc: 0.5088\n",
      "Epoch 217/800\n",
      "3200/3200 [==============================] - 1s 173us/step - loss: 1.9590 - acc: 0.4125 - val_loss: 1.7075 - val_acc: 0.5188\n",
      "Epoch 218/800\n",
      "3200/3200 [==============================] - 1s 177us/step - loss: 1.9171 - acc: 0.4181 - val_loss: 1.7022 - val_acc: 0.5100\n",
      "Epoch 219/800\n",
      "3200/3200 [==============================] - 1s 179us/step - loss: 1.9548 - acc: 0.4100 - val_loss: 1.7290 - val_acc: 0.5000\n",
      "Epoch 220/800\n",
      "3200/3200 [==============================] - 1s 179us/step - loss: 1.9582 - acc: 0.4178 - val_loss: 1.7585 - val_acc: 0.4950\n",
      "Epoch 221/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3200 [==============================] - 1s 173us/step - loss: 1.9287 - acc: 0.4134 - val_loss: 1.7011 - val_acc: 0.5262\n",
      "Epoch 222/800\n",
      "3200/3200 [==============================] - 1s 162us/step - loss: 1.9696 - acc: 0.4278 - val_loss: 1.7149 - val_acc: 0.5025\n",
      "Epoch 223/800\n",
      "3200/3200 [==============================] - 1s 157us/step - loss: 1.9382 - acc: 0.4272 - val_loss: 1.6910 - val_acc: 0.5188\n",
      "Epoch 224/800\n",
      "3200/3200 [==============================] - 1s 157us/step - loss: 1.9170 - acc: 0.4278 - val_loss: 1.6846 - val_acc: 0.5212\n",
      "Epoch 225/800\n",
      "3200/3200 [==============================] - 1s 164us/step - loss: 1.9588 - acc: 0.4294 - val_loss: 1.6948 - val_acc: 0.5162\n",
      "Epoch 226/800\n",
      "3200/3200 [==============================] - 1s 189us/step - loss: 1.9315 - acc: 0.4228 - val_loss: 1.7505 - val_acc: 0.5012\n",
      "Epoch 227/800\n",
      "3200/3200 [==============================] - 1s 172us/step - loss: 1.9727 - acc: 0.4141 - val_loss: 1.7162 - val_acc: 0.5025\n",
      "Epoch 228/800\n",
      "3200/3200 [==============================] - 1s 240us/step - loss: 1.9482 - acc: 0.4250 - val_loss: 1.7300 - val_acc: 0.4963\n",
      "Epoch 229/800\n",
      "3200/3200 [==============================] - 1s 187us/step - loss: 1.9502 - acc: 0.4175 - val_loss: 1.7115 - val_acc: 0.5312\n",
      "Epoch 230/800\n",
      "3200/3200 [==============================] - 1s 172us/step - loss: 1.9693 - acc: 0.4241 - val_loss: 1.7233 - val_acc: 0.5062\n",
      "Epoch 231/800\n",
      "3200/3200 [==============================] - 1s 190us/step - loss: 1.9157 - acc: 0.4263 - val_loss: 1.7039 - val_acc: 0.5150\n",
      "Epoch 232/800\n",
      "3200/3200 [==============================] - 1s 290us/step - loss: 1.8844 - acc: 0.4387 - val_loss: 1.6717 - val_acc: 0.5487\n",
      "Epoch 233/800\n",
      "3200/3200 [==============================] - 1s 224us/step - loss: 1.8939 - acc: 0.4244 - val_loss: 1.6857 - val_acc: 0.5463\n",
      "Epoch 234/800\n",
      "3200/3200 [==============================] - 1s 199us/step - loss: 1.9551 - acc: 0.4269 - val_loss: 1.6931 - val_acc: 0.5325\n",
      "Epoch 235/800\n",
      "3200/3200 [==============================] - 1s 210us/step - loss: 1.9272 - acc: 0.4316 - val_loss: 1.6747 - val_acc: 0.5200\n",
      "Epoch 236/800\n",
      "3200/3200 [==============================] - 1s 197us/step - loss: 1.8976 - acc: 0.4278 - val_loss: 1.6981 - val_acc: 0.5175\n",
      "Epoch 237/800\n",
      "3200/3200 [==============================] - 1s 162us/step - loss: 1.8757 - acc: 0.4387 - val_loss: 1.6965 - val_acc: 0.5225\n",
      "Epoch 238/800\n",
      "3200/3200 [==============================] - 1s 170us/step - loss: 1.9297 - acc: 0.4312 - val_loss: 1.7134 - val_acc: 0.5387\n",
      "Epoch 239/800\n",
      "3200/3200 [==============================] - 1s 187us/step - loss: 1.8959 - acc: 0.4409 - val_loss: 1.6391 - val_acc: 0.5500\n",
      "Epoch 240/800\n",
      "3200/3200 [==============================] - 1s 192us/step - loss: 1.9338 - acc: 0.4403 - val_loss: 1.6678 - val_acc: 0.5450\n",
      "Epoch 241/800\n",
      "3200/3200 [==============================] - 1s 207us/step - loss: 1.8707 - acc: 0.4472 - val_loss: 1.7037 - val_acc: 0.5062\n",
      "Epoch 242/800\n",
      "3200/3200 [==============================] - 1s 242us/step - loss: 1.8540 - acc: 0.4472 - val_loss: 1.6500 - val_acc: 0.5463\n",
      "Epoch 243/800\n",
      "3200/3200 [==============================] - 1s 237us/step - loss: 1.8949 - acc: 0.4425 - val_loss: 1.6581 - val_acc: 0.5513\n",
      "Epoch 244/800\n",
      "3200/3200 [==============================] - 1s 333us/step - loss: 1.8371 - acc: 0.4641 - val_loss: 1.6658 - val_acc: 0.5238\n",
      "Epoch 245/800\n",
      "3200/3200 [==============================] - 1s 263us/step - loss: 1.9385 - acc: 0.4319 - val_loss: 1.7062 - val_acc: 0.5050\n",
      "Epoch 246/800\n",
      "3200/3200 [==============================] - 1s 298us/step - loss: 1.9277 - acc: 0.4356 - val_loss: 1.7069 - val_acc: 0.5162\n",
      "Epoch 247/800\n",
      "3200/3200 [==============================] - 1s 389us/step - loss: 1.9044 - acc: 0.4372 - val_loss: 1.6803 - val_acc: 0.5288\n",
      "Epoch 248/800\n",
      "3200/3200 [==============================] - 1s 288us/step - loss: 1.8267 - acc: 0.4569 - val_loss: 1.6222 - val_acc: 0.5513\n",
      "Epoch 249/800\n",
      "3200/3200 [==============================] - 1s 212us/step - loss: 1.8426 - acc: 0.4550 - val_loss: 1.6412 - val_acc: 0.5463\n",
      "Epoch 250/800\n",
      "3200/3200 [==============================] - 1s 203us/step - loss: 1.8412 - acc: 0.4419 - val_loss: 1.5795 - val_acc: 0.5575\n",
      "Epoch 251/800\n",
      "3200/3200 [==============================] - 1s 269us/step - loss: 1.8603 - acc: 0.4544 - val_loss: 1.6323 - val_acc: 0.5613\n",
      "Epoch 252/800\n",
      "3200/3200 [==============================] - 1s 206us/step - loss: 1.8038 - acc: 0.4609 - val_loss: 1.6224 - val_acc: 0.5350\n",
      "Epoch 253/800\n",
      "3200/3200 [==============================] - 1s 318us/step - loss: 1.8205 - acc: 0.4537 - val_loss: 1.6176 - val_acc: 0.5500\n",
      "Epoch 254/800\n",
      "3200/3200 [==============================] - 1s 274us/step - loss: 1.8527 - acc: 0.4478 - val_loss: 1.6535 - val_acc: 0.5350\n",
      "Epoch 255/800\n",
      "3200/3200 [==============================] - 1s 211us/step - loss: 1.8208 - acc: 0.4650 - val_loss: 1.6037 - val_acc: 0.5613\n",
      "Epoch 256/800\n",
      "3200/3200 [==============================] - 1s 211us/step - loss: 1.8095 - acc: 0.4519 - val_loss: 1.6284 - val_acc: 0.5475\n",
      "Epoch 257/800\n",
      "3200/3200 [==============================] - 1s 206us/step - loss: 1.8377 - acc: 0.4525 - val_loss: 1.6180 - val_acc: 0.5537\n",
      "Epoch 258/800\n",
      "3200/3200 [==============================] - 1s 210us/step - loss: 1.8415 - acc: 0.4625 - val_loss: 1.6428 - val_acc: 0.5375\n",
      "Epoch 259/800\n",
      "3200/3200 [==============================] - 1s 332us/step - loss: 1.8288 - acc: 0.4616 - val_loss: 1.5775 - val_acc: 0.5575\n",
      "Epoch 260/800\n",
      "3200/3200 [==============================] - 1s 219us/step - loss: 1.8494 - acc: 0.4675 - val_loss: 1.6270 - val_acc: 0.5463\n",
      "Epoch 261/800\n",
      "3200/3200 [==============================] - 1s 211us/step - loss: 1.8126 - acc: 0.4559 - val_loss: 1.5893 - val_acc: 0.5737\n",
      "Epoch 262/800\n",
      "3200/3200 [==============================] - 1s 195us/step - loss: 1.8144 - acc: 0.4659 - val_loss: 1.6133 - val_acc: 0.5513\n",
      "Epoch 263/800\n",
      "3200/3200 [==============================] - 1s 231us/step - loss: 1.7932 - acc: 0.4594 - val_loss: 1.5848 - val_acc: 0.5813\n",
      "Epoch 264/800\n",
      "3200/3200 [==============================] - 1s 238us/step - loss: 1.7755 - acc: 0.4669 - val_loss: 1.5857 - val_acc: 0.5600\n",
      "Epoch 265/800\n",
      "3200/3200 [==============================] - 1s 236us/step - loss: 1.8190 - acc: 0.4662 - val_loss: 1.5753 - val_acc: 0.5713\n",
      "Epoch 266/800\n",
      "3200/3200 [==============================] - 1s 203us/step - loss: 1.7873 - acc: 0.4816 - val_loss: 1.5665 - val_acc: 0.5675\n",
      "Epoch 267/800\n",
      "3200/3200 [==============================] - 1s 263us/step - loss: 1.8319 - acc: 0.4597 - val_loss: 1.5803 - val_acc: 0.5763\n",
      "Epoch 268/800\n",
      "3200/3200 [==============================] - 1s 211us/step - loss: 1.7673 - acc: 0.4800 - val_loss: 1.5589 - val_acc: 0.5750\n",
      "Epoch 269/800\n",
      "3200/3200 [==============================] - 1s 195us/step - loss: 1.7584 - acc: 0.4781 - val_loss: 1.5650 - val_acc: 0.5613\n",
      "Epoch 270/800\n",
      "3200/3200 [==============================] - 1s 201us/step - loss: 1.7823 - acc: 0.4706 - val_loss: 1.5615 - val_acc: 0.5725\n",
      "Epoch 271/800\n",
      "3200/3200 [==============================] - 1s 219us/step - loss: 1.8280 - acc: 0.4766 - val_loss: 1.5355 - val_acc: 0.5763\n",
      "Epoch 272/800\n",
      "3200/3200 [==============================] - 1s 224us/step - loss: 1.7776 - acc: 0.4769 - val_loss: 1.5761 - val_acc: 0.5875\n",
      "Epoch 273/800\n",
      "3200/3200 [==============================] - 1s 203us/step - loss: 1.7543 - acc: 0.4841 - val_loss: 1.5868 - val_acc: 0.5650\n",
      "Epoch 274/800\n",
      "3200/3200 [==============================] - 1s 210us/step - loss: 1.7925 - acc: 0.4816 - val_loss: 1.5858 - val_acc: 0.5763\n",
      "Epoch 275/800\n",
      "3200/3200 [==============================] - 1s 273us/step - loss: 1.7509 - acc: 0.4763 - val_loss: 1.5457 - val_acc: 0.5687\n",
      "Epoch 276/800\n",
      "3200/3200 [==============================] - 1s 245us/step - loss: 1.8051 - acc: 0.4625 - val_loss: 1.5746 - val_acc: 0.5700\n",
      "Epoch 277/800\n",
      "3200/3200 [==============================] - 1s 240us/step - loss: 1.7236 - acc: 0.4822 - val_loss: 1.5302 - val_acc: 0.5837\n",
      "Epoch 278/800\n",
      "3200/3200 [==============================] - 1s 209us/step - loss: 1.7815 - acc: 0.4731 - val_loss: 1.5605 - val_acc: 0.5675\n",
      "Epoch 279/800\n",
      "3200/3200 [==============================] - 1s 271us/step - loss: 1.7686 - acc: 0.4778 - val_loss: 1.5536 - val_acc: 0.5550\n",
      "Epoch 280/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200/3200 [==============================] - 2s 726us/step - loss: 1.7914 - acc: 0.4697 - val_loss: 1.5570 - val_acc: 0.5600\n",
      "Epoch 281/800\n",
      "3200/3200 [==============================] - 1s 414us/step - loss: 1.7270 - acc: 0.5009 - val_loss: 1.5363 - val_acc: 0.5737\n",
      "Epoch 282/800\n",
      "3200/3200 [==============================] - 1s 444us/step - loss: 1.8136 - acc: 0.4759 - val_loss: 1.5355 - val_acc: 0.5675\n",
      "Epoch 283/800\n",
      "3200/3200 [==============================] - 1s 188us/step - loss: 1.7569 - acc: 0.4778 - val_loss: 1.5581 - val_acc: 0.5700\n",
      "Epoch 284/800\n",
      "3200/3200 [==============================] - 1s 187us/step - loss: 1.7860 - acc: 0.4809 - val_loss: 1.5372 - val_acc: 0.5613\n",
      "Epoch 285/800\n",
      "3200/3200 [==============================] - 1s 174us/step - loss: 1.7899 - acc: 0.4747 - val_loss: 1.5548 - val_acc: 0.5775\n",
      "Epoch 286/800\n",
      "3200/3200 [==============================] - 1s 174us/step - loss: 1.7642 - acc: 0.4747 - val_loss: 1.5322 - val_acc: 0.5775\n",
      "Epoch 287/800\n",
      "3200/3200 [==============================] - 1s 173us/step - loss: 1.7475 - acc: 0.4972 - val_loss: 1.5496 - val_acc: 0.5725\n",
      "Epoch 288/800\n",
      "3200/3200 [==============================] - 1s 181us/step - loss: 1.7439 - acc: 0.4878 - val_loss: 1.5261 - val_acc: 0.5687\n",
      "Epoch 289/800\n",
      "3200/3200 [==============================] - 1s 187us/step - loss: 1.7220 - acc: 0.4969 - val_loss: 1.5203 - val_acc: 0.5637\n",
      "Epoch 290/800\n",
      "3200/3200 [==============================] - 1s 164us/step - loss: 1.6918 - acc: 0.5000 - val_loss: 1.4857 - val_acc: 0.5988\n",
      "Epoch 291/800\n",
      "3200/3200 [==============================] - 1s 187us/step - loss: 1.7184 - acc: 0.5062 - val_loss: 1.5250 - val_acc: 0.5850\n",
      "Epoch 292/800\n",
      "3200/3200 [==============================] - 1s 177us/step - loss: 1.7814 - acc: 0.4797 - val_loss: 1.5365 - val_acc: 0.5863\n",
      "Epoch 293/800\n",
      "3200/3200 [==============================] - 1s 173us/step - loss: 1.7400 - acc: 0.4956 - val_loss: 1.5261 - val_acc: 0.5813\n",
      "Epoch 294/800\n",
      "3200/3200 [==============================] - 1s 170us/step - loss: 1.6720 - acc: 0.5100 - val_loss: 1.5089 - val_acc: 0.5887\n",
      "Epoch 295/800\n",
      "3200/3200 [==============================] - 1s 241us/step - loss: 1.6913 - acc: 0.5003 - val_loss: 1.4792 - val_acc: 0.6000\n",
      "Epoch 296/800\n",
      "3200/3200 [==============================] - 1s 221us/step - loss: 1.6948 - acc: 0.5034 - val_loss: 1.4694 - val_acc: 0.6138\n",
      "Epoch 297/800\n",
      "3200/3200 [==============================] - 1s 195us/step - loss: 1.7029 - acc: 0.4956 - val_loss: 1.4748 - val_acc: 0.5950\n",
      "Epoch 298/800\n",
      "3200/3200 [==============================] - 1s 176us/step - loss: 1.7008 - acc: 0.4828 - val_loss: 1.4866 - val_acc: 0.6112\n",
      "Epoch 299/800\n",
      "3200/3200 [==============================] - 1s 190us/step - loss: 1.6641 - acc: 0.5025 - val_loss: 1.4720 - val_acc: 0.5988\n",
      "Epoch 300/800\n",
      "3200/3200 [==============================] - 1s 172us/step - loss: 1.7062 - acc: 0.5122 - val_loss: 1.4678 - val_acc: 0.5875\n",
      "Epoch 301/800\n",
      "3200/3200 [==============================] - 1s 183us/step - loss: 1.7874 - acc: 0.4891 - val_loss: 1.5111 - val_acc: 0.5900\n",
      "Epoch 302/800\n",
      "3200/3200 [==============================] - 1s 181us/step - loss: 1.7064 - acc: 0.4950 - val_loss: 1.4602 - val_acc: 0.6038\n",
      "Epoch 303/800\n",
      "3200/3200 [==============================] - 1s 179us/step - loss: 1.6857 - acc: 0.4950 - val_loss: 1.4566 - val_acc: 0.6088\n",
      "Epoch 304/800\n",
      "3200/3200 [==============================] - 1s 202us/step - loss: 1.7170 - acc: 0.5034 - val_loss: 1.4580 - val_acc: 0.6112\n",
      "Epoch 305/800\n",
      "3200/3200 [==============================] - 1s 179us/step - loss: 1.7041 - acc: 0.4991 - val_loss: 1.5005 - val_acc: 0.5763\n",
      "Epoch 306/800\n",
      "3200/3200 [==============================] - 1s 182us/step - loss: 1.7109 - acc: 0.5012 - val_loss: 1.4745 - val_acc: 0.5875\n",
      "Epoch 307/800\n",
      "3200/3200 [==============================] - 1s 195us/step - loss: 1.7170 - acc: 0.4994 - val_loss: 1.4522 - val_acc: 0.5988\n",
      "Epoch 308/800\n",
      "3200/3200 [==============================] - 1s 190us/step - loss: 1.6844 - acc: 0.5019 - val_loss: 1.4340 - val_acc: 0.5938\n",
      "Epoch 309/800\n",
      "3200/3200 [==============================] - 1s 180us/step - loss: 1.6661 - acc: 0.5053 - val_loss: 1.4218 - val_acc: 0.6088\n",
      "Epoch 310/800\n",
      "3200/3200 [==============================] - 1s 182us/step - loss: 1.7272 - acc: 0.5028 - val_loss: 1.4564 - val_acc: 0.5887\n",
      "Epoch 311/800\n",
      "3200/3200 [==============================] - 1s 173us/step - loss: 1.6884 - acc: 0.5059 - val_loss: 1.4540 - val_acc: 0.5962\n",
      "Epoch 312/800\n",
      "3200/3200 [==============================] - 1s 190us/step - loss: 1.6403 - acc: 0.5212 - val_loss: 1.4462 - val_acc: 0.6162\n",
      "Epoch 313/800\n",
      "3200/3200 [==============================] - 1s 187us/step - loss: 1.6899 - acc: 0.5172 - val_loss: 1.5028 - val_acc: 0.5775\n",
      "Epoch 314/800\n",
      "3200/3200 [==============================] - 1s 190us/step - loss: 1.7237 - acc: 0.5025 - val_loss: 1.4511 - val_acc: 0.6162\n",
      "Epoch 315/800\n",
      "3200/3200 [==============================] - 1s 187us/step - loss: 1.6424 - acc: 0.5231 - val_loss: 1.4366 - val_acc: 0.6150\n",
      "Epoch 316/800\n",
      "3200/3200 [==============================] - 1s 194us/step - loss: 1.6680 - acc: 0.5062 - val_loss: 1.4357 - val_acc: 0.6050\n",
      "Epoch 317/800\n",
      "3200/3200 [==============================] - 1s 194us/step - loss: 1.6505 - acc: 0.5153 - val_loss: 1.4767 - val_acc: 0.5813\n",
      "Epoch 318/800\n",
      "3200/3200 [==============================] - ETA: 0s - loss: 1.6757 - acc: 0.513 - 1s 182us/step - loss: 1.6781 - acc: 0.5097 - val_loss: 1.5010 - val_acc: 0.5825\n",
      "Epoch 319/800\n",
      "3200/3200 [==============================] - 1s 198us/step - loss: 1.6777 - acc: 0.5112 - val_loss: 1.4585 - val_acc: 0.5975\n",
      "Epoch 320/800\n",
      "3200/3200 [==============================] - 1s 185us/step - loss: 1.6967 - acc: 0.5128 - val_loss: 1.4602 - val_acc: 0.5887\n",
      "Epoch 321/800\n",
      "3200/3200 [==============================] - 1s 250us/step - loss: 1.6587 - acc: 0.5100 - val_loss: 1.4592 - val_acc: 0.6050\n",
      "Epoch 322/800\n",
      "3200/3200 [==============================] - 1s 242us/step - loss: 1.7002 - acc: 0.5106 - val_loss: 1.4765 - val_acc: 0.5913\n",
      "Epoch 323/800\n",
      "3200/3200 [==============================] - 1s 186us/step - loss: 1.6342 - acc: 0.5238 - val_loss: 1.4794 - val_acc: 0.6038\n",
      "Epoch 324/800\n",
      "3200/3200 [==============================] - 1s 194us/step - loss: 1.6673 - acc: 0.5116 - val_loss: 1.4611 - val_acc: 0.6025\n",
      "Epoch 325/800\n",
      "3200/3200 [==============================] - 1s 185us/step - loss: 1.6608 - acc: 0.5122 - val_loss: 1.4358 - val_acc: 0.6262\n",
      "Epoch 326/800\n",
      "3200/3200 [==============================] - 1s 173us/step - loss: 1.6271 - acc: 0.5150 - val_loss: 1.4440 - val_acc: 0.6150\n",
      "Epoch 327/800\n",
      "3200/3200 [==============================] - 1s 212us/step - loss: 1.6776 - acc: 0.5134 - val_loss: 1.4402 - val_acc: 0.6162\n",
      "Epoch 328/800\n",
      "3200/3200 [==============================] - 1s 211us/step - loss: 1.6690 - acc: 0.5181 - val_loss: 1.4160 - val_acc: 0.6100\n",
      "Epoch 329/800\n",
      "3200/3200 [==============================] - 1s 206us/step - loss: 1.5925 - acc: 0.5309 - val_loss: 1.4350 - val_acc: 0.6100\n",
      "Epoch 330/800\n",
      "3200/3200 [==============================] - 1s 194us/step - loss: 1.6107 - acc: 0.5312 - val_loss: 1.4123 - val_acc: 0.6012\n",
      "Epoch 331/800\n",
      "3200/3200 [==============================] - 1s 203us/step - loss: 1.6291 - acc: 0.5256 - val_loss: 1.3949 - val_acc: 0.6188\n",
      "Epoch 332/800\n",
      "3200/3200 [==============================] - 1s 196us/step - loss: 1.6095 - acc: 0.5256 - val_loss: 1.4274 - val_acc: 0.5962\n",
      "Epoch 333/800\n",
      "3200/3200 [==============================] - 1s 205us/step - loss: 1.6409 - acc: 0.5244 - val_loss: 1.4027 - val_acc: 0.6112\n",
      "Epoch 334/800\n",
      "3200/3200 [==============================] - 1s 188us/step - loss: 1.6303 - acc: 0.5188 - val_loss: 1.4336 - val_acc: 0.6200\n",
      "Epoch 335/800\n",
      "3200/3200 [==============================] - 1s 207us/step - loss: 1.6205 - acc: 0.5169 - val_loss: 1.4475 - val_acc: 0.6050\n",
      "Epoch 336/800\n",
      "3200/3200 [==============================] - 1s 184us/step - loss: 1.6566 - acc: 0.5222 - val_loss: 1.4044 - val_acc: 0.6262\n",
      "Epoch 337/800\n",
      "3200/3200 [==============================] - 1s 214us/step - loss: 1.6631 - acc: 0.5134 - val_loss: 1.3921 - val_acc: 0.6188\n",
      "Epoch 338/800\n",
      "3200/3200 [==============================] - 1s 207us/step - loss: 1.6809 - acc: 0.5209 - val_loss: 1.4214 - val_acc: 0.6150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339/800\n",
      "3200/3200 [==============================] - 1s 174us/step - loss: 1.6622 - acc: 0.5138 - val_loss: 1.4184 - val_acc: 0.6000\n",
      "Epoch 340/800\n",
      "3200/3200 [==============================] - 1s 180us/step - loss: 1.6461 - acc: 0.5181 - val_loss: 1.4154 - val_acc: 0.6262\n",
      "Epoch 341/800\n",
      "3200/3200 [==============================] - 1s 191us/step - loss: 1.6272 - acc: 0.5322 - val_loss: 1.4307 - val_acc: 0.6100\n",
      "Epoch 342/800\n",
      "3200/3200 [==============================] - 1s 186us/step - loss: 1.5972 - acc: 0.5306 - val_loss: 1.4167 - val_acc: 0.6112\n",
      "Epoch 343/800\n",
      "3200/3200 [==============================] - 1s 183us/step - loss: 1.5848 - acc: 0.5406 - val_loss: 1.3851 - val_acc: 0.6138\n",
      "Epoch 344/800\n",
      "3200/3200 [==============================] - 1s 167us/step - loss: 1.6124 - acc: 0.5322 - val_loss: 1.3800 - val_acc: 0.6362\n",
      "Epoch 345/800\n",
      "3200/3200 [==============================] - 1s 176us/step - loss: 1.6474 - acc: 0.5166 - val_loss: 1.3855 - val_acc: 0.6212\n",
      "Epoch 346/800\n",
      "3200/3200 [==============================] - 1s 193us/step - loss: 1.5714 - acc: 0.5400 - val_loss: 1.3697 - val_acc: 0.6238\n",
      "Epoch 347/800\n",
      "3200/3200 [==============================] - 1s 250us/step - loss: 1.5975 - acc: 0.5413 - val_loss: 1.3793 - val_acc: 0.6312\n",
      "Epoch 348/800\n",
      "3200/3200 [==============================] - 1s 209us/step - loss: 1.6428 - acc: 0.5156 - val_loss: 1.3802 - val_acc: 0.6425\n",
      "Epoch 349/800\n",
      "3200/3200 [==============================] - 1s 184us/step - loss: 1.6113 - acc: 0.5316 - val_loss: 1.3605 - val_acc: 0.6438\n",
      "Epoch 350/800\n",
      "3200/3200 [==============================] - 1s 182us/step - loss: 1.6314 - acc: 0.5356 - val_loss: 1.3904 - val_acc: 0.6162\n",
      "Epoch 351/800\n",
      "3200/3200 [==============================] - 1s 195us/step - loss: 1.5983 - acc: 0.5422 - val_loss: 1.3714 - val_acc: 0.6412\n",
      "Epoch 352/800\n",
      "3200/3200 [==============================] - 1s 180us/step - loss: 1.6258 - acc: 0.5350 - val_loss: 1.3724 - val_acc: 0.6250\n",
      "Epoch 353/800\n",
      "3200/3200 [==============================] - 1s 172us/step - loss: 1.5905 - acc: 0.5341 - val_loss: 1.3375 - val_acc: 0.6300\n",
      "Epoch 354/800\n",
      "3200/3200 [==============================] - 1s 189us/step - loss: 1.6000 - acc: 0.5400 - val_loss: 1.3866 - val_acc: 0.6138\n",
      "Epoch 355/800\n",
      "3200/3200 [==============================] - 1s 181us/step - loss: 1.5809 - acc: 0.5384 - val_loss: 1.3850 - val_acc: 0.6362\n",
      "Epoch 356/800\n",
      "3200/3200 [==============================] - 1s 183us/step - loss: 1.6155 - acc: 0.5297 - val_loss: 1.3617 - val_acc: 0.6375\n",
      "Epoch 357/800\n",
      "3200/3200 [==============================] - 1s 181us/step - loss: 1.5956 - acc: 0.5391 - val_loss: 1.3912 - val_acc: 0.6338\n",
      "Epoch 358/800\n",
      "3200/3200 [==============================] - 1s 190us/step - loss: 1.5629 - acc: 0.5497 - val_loss: 1.3802 - val_acc: 0.6438\n",
      "Epoch 359/800\n",
      "3200/3200 [==============================] - 1s 177us/step - loss: 1.5631 - acc: 0.5441 - val_loss: 1.3881 - val_acc: 0.6438\n",
      "Epoch 360/800\n",
      "3200/3200 [==============================] - 1s 183us/step - loss: 1.5853 - acc: 0.5372 - val_loss: 1.4317 - val_acc: 0.6300\n",
      "Epoch 361/800\n",
      "3200/3200 [==============================] - 1s 178us/step - loss: 1.6014 - acc: 0.5341 - val_loss: 1.3636 - val_acc: 0.6438\n",
      "Epoch 362/800\n",
      "3200/3200 [==============================] - 1s 189us/step - loss: 1.5569 - acc: 0.5463 - val_loss: 1.3637 - val_acc: 0.6388\n",
      "Epoch 363/800\n",
      "3200/3200 [==============================] - 1s 177us/step - loss: 1.5860 - acc: 0.5531 - val_loss: 1.3750 - val_acc: 0.6475\n",
      "Epoch 364/800\n",
      "3200/3200 [==============================] - 1s 174us/step - loss: 1.5923 - acc: 0.5525 - val_loss: 1.3849 - val_acc: 0.6438\n",
      "Epoch 365/800\n",
      "3200/3200 [==============================] - 1s 191us/step - loss: 1.6073 - acc: 0.5322 - val_loss: 1.3733 - val_acc: 0.6288\n",
      "Epoch 366/800\n",
      "3200/3200 [==============================] - 1s 176us/step - loss: 1.5967 - acc: 0.5366 - val_loss: 1.3547 - val_acc: 0.6262\n",
      "Epoch 367/800\n",
      "3200/3200 [==============================] - 1s 185us/step - loss: 1.5812 - acc: 0.5431 - val_loss: 1.3744 - val_acc: 0.6312\n",
      "Epoch 368/800\n",
      "3200/3200 [==============================] - 1s 185us/step - loss: 1.5919 - acc: 0.5450 - val_loss: 1.3372 - val_acc: 0.6325\n",
      "Epoch 369/800\n",
      "3200/3200 [==============================] - 1s 196us/step - loss: 1.5091 - acc: 0.5531 - val_loss: 1.3438 - val_acc: 0.6300\n",
      "Epoch 370/800\n",
      "3200/3200 [==============================] - 1s 171us/step - loss: 1.5560 - acc: 0.5500 - val_loss: 1.3425 - val_acc: 0.6362\n",
      "Epoch 371/800\n",
      "3200/3200 [==============================] - 1s 211us/step - loss: 1.5798 - acc: 0.5503 - val_loss: 1.3326 - val_acc: 0.6388\n",
      "Epoch 372/800\n",
      "3200/3200 [==============================] - 1s 190us/step - loss: 1.5688 - acc: 0.5491 - val_loss: 1.3575 - val_acc: 0.6150\n",
      "Epoch 373/800\n",
      "3200/3200 [==============================] - 1s 236us/step - loss: 1.5618 - acc: 0.5516 - val_loss: 1.3672 - val_acc: 0.6388\n",
      "Epoch 374/800\n",
      "3200/3200 [==============================] - 1s 240us/step - loss: 1.5601 - acc: 0.5450 - val_loss: 1.3668 - val_acc: 0.6325\n",
      "Epoch 375/800\n",
      "3200/3200 [==============================] - 1s 197us/step - loss: 1.5546 - acc: 0.5578 - val_loss: 1.3542 - val_acc: 0.6312\n",
      "Epoch 376/800\n",
      "3200/3200 [==============================] - 1s 191us/step - loss: 1.5811 - acc: 0.5550 - val_loss: 1.3330 - val_acc: 0.6262\n",
      "Epoch 377/800\n",
      "3200/3200 [==============================] - 1s 185us/step - loss: 1.5389 - acc: 0.5509 - val_loss: 1.3382 - val_acc: 0.6438\n",
      "Epoch 378/800\n",
      "3200/3200 [==============================] - 1s 186us/step - loss: 1.5662 - acc: 0.5487 - val_loss: 1.3551 - val_acc: 0.6300\n",
      "Epoch 379/800\n",
      "3200/3200 [==============================] - 1s 198us/step - loss: 1.4892 - acc: 0.5566 - val_loss: 1.3257 - val_acc: 0.6350\n",
      "Epoch 380/800\n",
      "3200/3200 [==============================] - 1s 187us/step - loss: 1.5476 - acc: 0.5563 - val_loss: 1.3071 - val_acc: 0.6462\n",
      "Epoch 381/800\n",
      "3200/3200 [==============================] - 1s 192us/step - loss: 1.5342 - acc: 0.5584 - val_loss: 1.3355 - val_acc: 0.6425\n",
      "Epoch 382/800\n",
      "3200/3200 [==============================] - 1s 191us/step - loss: 1.5573 - acc: 0.5466 - val_loss: 1.3374 - val_acc: 0.6375\n",
      "Epoch 383/800\n",
      "3200/3200 [==============================] - 1s 190us/step - loss: 1.5417 - acc: 0.5584 - val_loss: 1.3030 - val_acc: 0.6300\n",
      "Epoch 384/800\n",
      "3200/3200 [==============================] - 1s 187us/step - loss: 1.5862 - acc: 0.5397 - val_loss: 1.3293 - val_acc: 0.6425\n",
      "Epoch 385/800\n",
      "3200/3200 [==============================] - 1s 187us/step - loss: 1.5422 - acc: 0.5563 - val_loss: 1.3667 - val_acc: 0.6288\n",
      "Epoch 386/800\n",
      "3200/3200 [==============================] - 1s 180us/step - loss: 1.5523 - acc: 0.5503 - val_loss: 1.3359 - val_acc: 0.6400\n",
      "Epoch 387/800\n",
      "3200/3200 [==============================] - 1s 184us/step - loss: 1.5823 - acc: 0.5397 - val_loss: 1.3221 - val_acc: 0.6538\n",
      "Epoch 388/800\n",
      "3200/3200 [==============================] - 1s 203us/step - loss: 1.5224 - acc: 0.5534 - val_loss: 1.3373 - val_acc: 0.6412\n",
      "Epoch 389/800\n",
      "3200/3200 [==============================] - 1s 185us/step - loss: 1.5246 - acc: 0.5628 - val_loss: 1.3118 - val_acc: 0.6538\n",
      "Epoch 390/800\n",
      "3200/3200 [==============================] - 1s 206us/step - loss: 1.5333 - acc: 0.5666 - val_loss: 1.3360 - val_acc: 0.6325\n",
      "Epoch 391/800\n",
      "3200/3200 [==============================] - 1s 189us/step - loss: 1.5511 - acc: 0.5469 - val_loss: 1.3292 - val_acc: 0.6225\n",
      "Epoch 392/800\n",
      "3200/3200 [==============================] - 1s 209us/step - loss: 1.5183 - acc: 0.5587 - val_loss: 1.3496 - val_acc: 0.6262\n",
      "Epoch 393/800\n",
      "3200/3200 [==============================] - 1s 191us/step - loss: 1.5644 - acc: 0.5450 - val_loss: 1.3236 - val_acc: 0.6500\n",
      "Epoch 394/800\n",
      "3200/3200 [==============================] - 1s 207us/step - loss: 1.5243 - acc: 0.5537 - val_loss: 1.3010 - val_acc: 0.6525\n",
      "Epoch 395/800\n",
      "3200/3200 [==============================] - 1s 197us/step - loss: 1.5253 - acc: 0.5566 - val_loss: 1.2905 - val_acc: 0.6438\n",
      "Epoch 396/800\n",
      "3200/3200 [==============================] - 1s 195us/step - loss: 1.5638 - acc: 0.5469 - val_loss: 1.2935 - val_acc: 0.6525\n",
      "Epoch 397/800\n",
      "3200/3200 [==============================] - 1s 194us/step - loss: 1.5357 - acc: 0.5478 - val_loss: 1.2910 - val_acc: 0.6538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398/800\n",
      "3200/3200 [==============================] - 1s 210us/step - loss: 1.5458 - acc: 0.5675 - val_loss: 1.2962 - val_acc: 0.6450\n",
      "Epoch 399/800\n",
      "3200/3200 [==============================] - 1s 230us/step - loss: 1.5060 - acc: 0.5703 - val_loss: 1.2998 - val_acc: 0.6675\n",
      "Epoch 400/800\n",
      "3200/3200 [==============================] - 1s 185us/step - loss: 1.5321 - acc: 0.5497 - val_loss: 1.3065 - val_acc: 0.6288\n",
      "Epoch 401/800\n",
      "3200/3200 [==============================] - 1s 179us/step - loss: 1.5384 - acc: 0.5547 - val_loss: 1.3484 - val_acc: 0.6450\n",
      "Epoch 402/800\n",
      "3200/3200 [==============================] - 1s 180us/step - loss: 1.5326 - acc: 0.5516 - val_loss: 1.3070 - val_acc: 0.6475\n",
      "Epoch 403/800\n",
      "3200/3200 [==============================] - 1s 182us/step - loss: 1.4984 - acc: 0.5559 - val_loss: 1.3679 - val_acc: 0.6188\n",
      "Epoch 404/800\n",
      "3200/3200 [==============================] - 1s 178us/step - loss: 1.5108 - acc: 0.5687 - val_loss: 1.2957 - val_acc: 0.6425\n",
      "Epoch 405/800\n",
      "3200/3200 [==============================] - 1s 186us/step - loss: 1.4770 - acc: 0.5694 - val_loss: 1.3039 - val_acc: 0.6587\n",
      "Epoch 406/800\n",
      "3200/3200 [==============================] - 1s 185us/step - loss: 1.4734 - acc: 0.5672 - val_loss: 1.3456 - val_acc: 0.6462\n",
      "Epoch 407/800\n",
      "3200/3200 [==============================] - 1s 207us/step - loss: 1.5088 - acc: 0.5644 - val_loss: 1.3003 - val_acc: 0.6488\n",
      "Epoch 408/800\n",
      "3200/3200 [==============================] - 1s 194us/step - loss: 1.5068 - acc: 0.5709 - val_loss: 1.2920 - val_acc: 0.6475\n",
      "Epoch 409/800\n",
      "3200/3200 [==============================] - 1s 399us/step - loss: 1.5159 - acc: 0.5591 - val_loss: 1.3170 - val_acc: 0.6562\n",
      "Epoch 410/800\n",
      "3200/3200 [==============================] - 1s 316us/step - loss: 1.5169 - acc: 0.5734 - val_loss: 1.3025 - val_acc: 0.6450\n",
      "Epoch 411/800\n",
      "3200/3200 [==============================] - 1s 203us/step - loss: 1.5449 - acc: 0.5597 - val_loss: 1.3474 - val_acc: 0.6425\n",
      "Epoch 412/800\n",
      "3200/3200 [==============================] - 1s 234us/step - loss: 1.4826 - acc: 0.5744 - val_loss: 1.3479 - val_acc: 0.6388\n",
      "Epoch 413/800\n",
      "3200/3200 [==============================] - 1s 224us/step - loss: 1.4660 - acc: 0.5766 - val_loss: 1.3205 - val_acc: 0.6362\n",
      "Epoch 414/800\n",
      "3200/3200 [==============================] - 1s 327us/step - loss: 1.4670 - acc: 0.5681 - val_loss: 1.2965 - val_acc: 0.6613\n",
      "Epoch 415/800\n",
      "3200/3200 [==============================] - 1s 209us/step - loss: 1.4789 - acc: 0.5663 - val_loss: 1.3137 - val_acc: 0.6438\n",
      "Epoch 416/800\n",
      "3200/3200 [==============================] - 1s 239us/step - loss: 1.4810 - acc: 0.5741 - val_loss: 1.3668 - val_acc: 0.6450\n",
      "Epoch 417/800\n",
      "3200/3200 [==============================] - 1s 185us/step - loss: 1.5254 - acc: 0.5637 - val_loss: 1.3426 - val_acc: 0.6325\n",
      "Epoch 418/800\n",
      "3200/3200 [==============================] - 1s 181us/step - loss: 1.4897 - acc: 0.5713 - val_loss: 1.3171 - val_acc: 0.6338\n",
      "Epoch 419/800\n",
      "3200/3200 [==============================] - 1s 200us/step - loss: 1.5081 - acc: 0.5713 - val_loss: 1.3305 - val_acc: 0.6462\n",
      "Epoch 420/800\n",
      "3200/3200 [==============================] - 1s 181us/step - loss: 1.5124 - acc: 0.5641 - val_loss: 1.2866 - val_acc: 0.6550\n",
      "Epoch 421/800\n",
      "3200/3200 [==============================] - 1s 239us/step - loss: 1.5145 - acc: 0.5678 - val_loss: 1.3128 - val_acc: 0.6425\n",
      "Epoch 422/800\n",
      "3200/3200 [==============================] - 1s 257us/step - loss: 1.4232 - acc: 0.5731 - val_loss: 1.2835 - val_acc: 0.6500\n",
      "Epoch 423/800\n",
      "3200/3200 [==============================] - 1s 214us/step - loss: 1.4527 - acc: 0.5750 - val_loss: 1.2942 - val_acc: 0.6525\n",
      "Epoch 424/800\n",
      "3200/3200 [==============================] - 1s 188us/step - loss: 1.4902 - acc: 0.5703 - val_loss: 1.2786 - val_acc: 0.6562\n",
      "Epoch 425/800\n",
      "3200/3200 [==============================] - 1s 189us/step - loss: 1.4871 - acc: 0.5713 - val_loss: 1.2910 - val_acc: 0.6438\n",
      "Epoch 426/800\n",
      "3200/3200 [==============================] - 1s 200us/step - loss: 1.5333 - acc: 0.5597 - val_loss: 1.3429 - val_acc: 0.6462\n",
      "Epoch 427/800\n",
      "3200/3200 [==============================] - 1s 180us/step - loss: 1.5074 - acc: 0.5809 - val_loss: 1.2951 - val_acc: 0.6488\n",
      "Epoch 428/800\n",
      "3200/3200 [==============================] - 1s 187us/step - loss: 1.4527 - acc: 0.5734 - val_loss: 1.2989 - val_acc: 0.6675\n",
      "Epoch 429/800\n",
      "3200/3200 [==============================] - 1s 198us/step - loss: 1.5619 - acc: 0.5641 - val_loss: 1.3316 - val_acc: 0.6550\n",
      "Epoch 430/800\n",
      "3200/3200 [==============================] - 1s 189us/step - loss: 1.4886 - acc: 0.5813 - val_loss: 1.2864 - val_acc: 0.6625\n",
      "Epoch 431/800\n",
      "3200/3200 [==============================] - 1s 206us/step - loss: 1.5005 - acc: 0.5741 - val_loss: 1.3067 - val_acc: 0.6700\n",
      "Epoch 432/800\n",
      "3200/3200 [==============================] - 1s 192us/step - loss: 1.5145 - acc: 0.5609 - val_loss: 1.3114 - val_acc: 0.6375\n",
      "Epoch 433/800\n",
      "3200/3200 [==============================] - 1s 193us/step - loss: 1.5072 - acc: 0.5684 - val_loss: 1.2718 - val_acc: 0.6737\n",
      "Epoch 434/800\n",
      "3200/3200 [==============================] - 1s 199us/step - loss: 1.4729 - acc: 0.5828 - val_loss: 1.3017 - val_acc: 0.6562\n",
      "Epoch 435/800\n",
      "3200/3200 [==============================] - 1s 204us/step - loss: 1.4929 - acc: 0.5716 - val_loss: 1.2617 - val_acc: 0.6625\n",
      "Epoch 436/800\n",
      "3200/3200 [==============================] - 1s 188us/step - loss: 1.4650 - acc: 0.5784 - val_loss: 1.3309 - val_acc: 0.6350\n",
      "Epoch 437/800\n",
      "3200/3200 [==============================] - 1s 191us/step - loss: 1.4513 - acc: 0.5878 - val_loss: 1.2745 - val_acc: 0.6700\n",
      "Epoch 438/800\n",
      "3200/3200 [==============================] - 1s 196us/step - loss: 1.4722 - acc: 0.5856 - val_loss: 1.2488 - val_acc: 0.6713\n",
      "Epoch 439/800\n",
      "3200/3200 [==============================] - 1s 230us/step - loss: 1.4644 - acc: 0.5841 - val_loss: 1.2501 - val_acc: 0.6625\n",
      "Epoch 440/800\n",
      "3200/3200 [==============================] - 1s 228us/step - loss: 1.4687 - acc: 0.5741 - val_loss: 1.2627 - val_acc: 0.6687\n",
      "Epoch 441/800\n",
      "3200/3200 [==============================] - 1s 194us/step - loss: 1.4833 - acc: 0.5725 - val_loss: 1.2520 - val_acc: 0.6813\n",
      "Epoch 442/800\n",
      "3200/3200 [==============================] - 1s 194us/step - loss: 1.4237 - acc: 0.5822 - val_loss: 1.2565 - val_acc: 0.6900\n",
      "Epoch 443/800\n",
      "3200/3200 [==============================] - 1s 199us/step - loss: 1.4835 - acc: 0.5803 - val_loss: 1.2727 - val_acc: 0.6663\n",
      "Epoch 444/800\n",
      "3200/3200 [==============================] - 1s 200us/step - loss: 1.4557 - acc: 0.5797 - val_loss: 1.2533 - val_acc: 0.6687\n",
      "Epoch 445/800\n",
      "3200/3200 [==============================] - 1s 200us/step - loss: 1.5241 - acc: 0.5687 - val_loss: 1.3048 - val_acc: 0.6550\n",
      "Epoch 446/800\n",
      "3200/3200 [==============================] - 1s 258us/step - loss: 1.4587 - acc: 0.5722 - val_loss: 1.2695 - val_acc: 0.6600\n",
      "Epoch 447/800\n",
      "3200/3200 [==============================] - 1s 240us/step - loss: 1.4643 - acc: 0.5784 - val_loss: 1.3035 - val_acc: 0.6500\n",
      "Epoch 448/800\n",
      "3200/3200 [==============================] - 1s 221us/step - loss: 1.4361 - acc: 0.5894 - val_loss: 1.2859 - val_acc: 0.6587\n",
      "Epoch 449/800\n",
      "3200/3200 [==============================] - 1s 244us/step - loss: 1.4523 - acc: 0.5713 - val_loss: 1.2825 - val_acc: 0.6613\n",
      "Epoch 450/800\n",
      "3200/3200 [==============================] - 1s 215us/step - loss: 1.4371 - acc: 0.5781 - val_loss: 1.2814 - val_acc: 0.6550\n",
      "Epoch 451/800\n",
      "3200/3200 [==============================] - 1s 185us/step - loss: 1.4504 - acc: 0.5878 - val_loss: 1.2713 - val_acc: 0.6675\n",
      "Epoch 452/800\n",
      "3200/3200 [==============================] - 1s 210us/step - loss: 1.4904 - acc: 0.5684 - val_loss: 1.2707 - val_acc: 0.6538\n",
      "Epoch 453/800\n",
      "3200/3200 [==============================] - 1s 198us/step - loss: 1.4349 - acc: 0.5822 - val_loss: 1.2766 - val_acc: 0.6562\n",
      "Epoch 454/800\n",
      "3200/3200 [==============================] - 1s 196us/step - loss: 1.4639 - acc: 0.5756 - val_loss: 1.2492 - val_acc: 0.6713\n",
      "Epoch 455/800\n",
      "3200/3200 [==============================] - 1s 197us/step - loss: 1.4335 - acc: 0.5872 - val_loss: 1.2813 - val_acc: 0.6488\n",
      "Epoch 456/800\n",
      "3200/3200 [==============================] - 1s 210us/step - loss: 1.4710 - acc: 0.5756 - val_loss: 1.2421 - val_acc: 0.6700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/800\n",
      "3200/3200 [==============================] - 1s 193us/step - loss: 1.4441 - acc: 0.5891 - val_loss: 1.2305 - val_acc: 0.6725\n",
      "Epoch 458/800\n",
      "3200/3200 [==============================] - 1s 181us/step - loss: 1.4450 - acc: 0.5869 - val_loss: 1.2906 - val_acc: 0.6663\n",
      "Epoch 459/800\n",
      "3200/3200 [==============================] - 1s 173us/step - loss: 1.4386 - acc: 0.5863 - val_loss: 1.2571 - val_acc: 0.6800\n",
      "Epoch 460/800\n",
      "3200/3200 [==============================] - 1s 179us/step - loss: 1.4630 - acc: 0.5869 - val_loss: 1.2685 - val_acc: 0.6575\n",
      "Epoch 461/800\n",
      "3200/3200 [==============================] - 1s 179us/step - loss: 1.4606 - acc: 0.5750 - val_loss: 1.2800 - val_acc: 0.6500\n",
      "Epoch 462/800\n",
      "3200/3200 [==============================] - 1s 178us/step - loss: 1.4581 - acc: 0.5950 - val_loss: 1.2632 - val_acc: 0.6713\n",
      "Epoch 463/800\n",
      "3200/3200 [==============================] - 1s 188us/step - loss: 1.4322 - acc: 0.5856 - val_loss: 1.2512 - val_acc: 0.6637\n",
      "Epoch 464/800\n",
      "3200/3200 [==============================] - 1s 167us/step - loss: 1.4190 - acc: 0.5963 - val_loss: 1.2497 - val_acc: 0.6550\n",
      "Epoch 465/800\n",
      "3200/3200 [==============================] - 1s 176us/step - loss: 1.4618 - acc: 0.5906 - val_loss: 1.2536 - val_acc: 0.6725\n",
      "Epoch 466/800\n",
      "3200/3200 [==============================] - 1s 177us/step - loss: 1.4973 - acc: 0.5809 - val_loss: 1.2798 - val_acc: 0.6763\n",
      "Epoch 467/800\n",
      "3200/3200 [==============================] - 1s 177us/step - loss: 1.3793 - acc: 0.6050 - val_loss: 1.2183 - val_acc: 0.6663\n",
      "Epoch 468/800\n",
      "3200/3200 [==============================] - 1s 183us/step - loss: 1.4645 - acc: 0.5859 - val_loss: 1.2714 - val_acc: 0.6450\n",
      "Epoch 469/800\n",
      "3200/3200 [==============================] - 1s 180us/step - loss: 1.5128 - acc: 0.5784 - val_loss: 1.2925 - val_acc: 0.6587\n",
      "Epoch 470/800\n",
      "3200/3200 [==============================] - 1s 183us/step - loss: 1.4268 - acc: 0.5903 - val_loss: 1.2303 - val_acc: 0.6787\n",
      "Epoch 471/800\n",
      "3200/3200 [==============================] - 1s 207us/step - loss: 1.4622 - acc: 0.5900 - val_loss: 1.2036 - val_acc: 0.6637\n",
      "Epoch 472/800\n",
      "3200/3200 [==============================] - 1s 241us/step - loss: 1.4083 - acc: 0.6006 - val_loss: 1.2283 - val_acc: 0.6613\n",
      "Epoch 473/800\n",
      "3200/3200 [==============================] - 1s 180us/step - loss: 1.4373 - acc: 0.5834 - val_loss: 1.2736 - val_acc: 0.6650\n",
      "Epoch 474/800\n",
      "3200/3200 [==============================] - 1s 183us/step - loss: 1.4096 - acc: 0.5963 - val_loss: 1.2174 - val_acc: 0.6813\n",
      "Epoch 475/800\n",
      "3200/3200 [==============================] - 1s 183us/step - loss: 1.4250 - acc: 0.5950 - val_loss: 1.2423 - val_acc: 0.6637\n",
      "Epoch 476/800\n",
      "3200/3200 [==============================] - 1s 179us/step - loss: 1.3906 - acc: 0.5941 - val_loss: 1.2317 - val_acc: 0.6625\n",
      "Epoch 477/800\n",
      "3200/3200 [==============================] - 1s 198us/step - loss: 1.4264 - acc: 0.5834 - val_loss: 1.2951 - val_acc: 0.6687\n",
      "Epoch 478/800\n",
      "3200/3200 [==============================] - 1s 187us/step - loss: 1.4703 - acc: 0.5909 - val_loss: 1.2266 - val_acc: 0.6713\n",
      "Epoch 479/800\n",
      "3200/3200 [==============================] - 1s 177us/step - loss: 1.3949 - acc: 0.5966 - val_loss: 1.2397 - val_acc: 0.6800\n",
      "Epoch 480/800\n",
      "3200/3200 [==============================] - 1s 187us/step - loss: 1.3941 - acc: 0.5934 - val_loss: 1.2143 - val_acc: 0.6737\n",
      "Epoch 481/800\n",
      "3200/3200 [==============================] - 1s 181us/step - loss: 1.4123 - acc: 0.6012 - val_loss: 1.2211 - val_acc: 0.6613\n",
      "Epoch 482/800\n",
      "3200/3200 [==============================] - 1s 176us/step - loss: 1.4040 - acc: 0.5903 - val_loss: 1.2028 - val_acc: 0.6825\n",
      "Epoch 483/800\n",
      "3200/3200 [==============================] - 1s 190us/step - loss: 1.4272 - acc: 0.5841 - val_loss: 1.2319 - val_acc: 0.6725\n",
      "Epoch 484/800\n",
      "3200/3200 [==============================] - 1s 178us/step - loss: 1.4444 - acc: 0.5931 - val_loss: 1.2646 - val_acc: 0.6562\n",
      "Epoch 485/800\n",
      "3200/3200 [==============================] - 1s 190us/step - loss: 1.3886 - acc: 0.5947 - val_loss: 1.2372 - val_acc: 0.6713\n",
      "Epoch 486/800\n",
      "3200/3200 [==============================] - 1s 187us/step - loss: 1.3889 - acc: 0.6050 - val_loss: 1.1955 - val_acc: 0.7000\n",
      "Epoch 487/800\n",
      "3200/3200 [==============================] - 1s 194us/step - loss: 1.3789 - acc: 0.6103 - val_loss: 1.1965 - val_acc: 0.6863\n",
      "Epoch 488/800\n",
      "3200/3200 [==============================] - 1s 183us/step - loss: 1.4153 - acc: 0.5994 - val_loss: 1.1664 - val_acc: 0.6725\n",
      "Epoch 489/800\n",
      "3200/3200 [==============================] - 1s 189us/step - loss: 1.4387 - acc: 0.5928 - val_loss: 1.1939 - val_acc: 0.6825\n",
      "Epoch 490/800\n",
      "3200/3200 [==============================] - 1s 185us/step - loss: 1.4001 - acc: 0.6047 - val_loss: 1.2334 - val_acc: 0.6763\n",
      "Epoch 491/800\n",
      "3200/3200 [==============================] - 1s 190us/step - loss: 1.3756 - acc: 0.6031 - val_loss: 1.2142 - val_acc: 0.6850\n",
      "Epoch 492/800\n",
      "3200/3200 [==============================] - 1s 189us/step - loss: 1.4212 - acc: 0.5956 - val_loss: 1.2283 - val_acc: 0.6813\n",
      "Epoch 493/800\n",
      "3200/3200 [==============================] - 1s 185us/step - loss: 1.4163 - acc: 0.6050 - val_loss: 1.1735 - val_acc: 0.6875\n",
      "Epoch 494/800\n",
      "3200/3200 [==============================] - 1s 174us/step - loss: 1.3716 - acc: 0.5981 - val_loss: 1.2389 - val_acc: 0.6800\n",
      "Epoch 495/800\n",
      "3200/3200 [==============================] - 1s 190us/step - loss: 1.4102 - acc: 0.6038 - val_loss: 1.2480 - val_acc: 0.6837\n",
      "Epoch 496/800\n",
      "3200/3200 [==============================] - 1s 187us/step - loss: 1.4438 - acc: 0.6053 - val_loss: 1.1975 - val_acc: 0.6787\n",
      "Epoch 497/800\n",
      "3200/3200 [==============================] - 1s 193us/step - loss: 1.4315 - acc: 0.5997 - val_loss: 1.2149 - val_acc: 0.6763\n",
      "Epoch 498/800\n",
      "3200/3200 [==============================] - 1s 245us/step - loss: 1.4258 - acc: 0.6053 - val_loss: 1.2122 - val_acc: 0.6850\n",
      "Epoch 499/800\n",
      "3200/3200 [==============================] - 1s 238us/step - loss: 1.4554 - acc: 0.5978 - val_loss: 1.2096 - val_acc: 0.6763\n",
      "Epoch 500/800\n",
      "3200/3200 [==============================] - 1s 193us/step - loss: 1.4081 - acc: 0.6038 - val_loss: 1.2314 - val_acc: 0.6625\n",
      "Epoch 501/800\n",
      "3200/3200 [==============================] - 1s 190us/step - loss: 1.4244 - acc: 0.5844 - val_loss: 1.2441 - val_acc: 0.6813\n",
      "Epoch 502/800\n",
      "3200/3200 [==============================] - 1s 184us/step - loss: 1.4427 - acc: 0.5894 - val_loss: 1.2231 - val_acc: 0.6700\n",
      "Epoch 503/800\n",
      "3200/3200 [==============================] - 1s 198us/step - loss: 1.3617 - acc: 0.6200 - val_loss: 1.1932 - val_acc: 0.6863\n",
      "Epoch 504/800\n",
      "3200/3200 [==============================] - 1s 188us/step - loss: 1.3904 - acc: 0.5991 - val_loss: 1.1900 - val_acc: 0.6813\n",
      "Epoch 505/800\n",
      "3200/3200 [==============================] - 1s 183us/step - loss: 1.3962 - acc: 0.6122 - val_loss: 1.1988 - val_acc: 0.6863\n",
      "Epoch 506/800\n",
      "3200/3200 [==============================] - 1s 206us/step - loss: 1.3894 - acc: 0.6006 - val_loss: 1.2441 - val_acc: 0.6725\n",
      "Epoch 507/800\n",
      "3200/3200 [==============================] - 1s 184us/step - loss: 1.4145 - acc: 0.5981 - val_loss: 1.2461 - val_acc: 0.6763\n",
      "Epoch 508/800\n",
      "3200/3200 [==============================] - 1s 197us/step - loss: 1.4383 - acc: 0.6009 - val_loss: 1.2064 - val_acc: 0.6913\n",
      "Epoch 509/800\n",
      "3200/3200 [==============================] - 1s 194us/step - loss: 1.4071 - acc: 0.6047 - val_loss: 1.1971 - val_acc: 0.6875\n",
      "Epoch 510/800\n",
      "3200/3200 [==============================] - 1s 196us/step - loss: 1.4078 - acc: 0.6025 - val_loss: 1.1846 - val_acc: 0.6975\n",
      "Epoch 511/800\n",
      "3200/3200 [==============================] - 1s 191us/step - loss: 1.4345 - acc: 0.5925 - val_loss: 1.2421 - val_acc: 0.6813\n",
      "Epoch 512/800\n",
      "3200/3200 [==============================] - 1s 204us/step - loss: 1.4753 - acc: 0.5806 - val_loss: 1.2280 - val_acc: 0.6837\n",
      "Epoch 513/800\n",
      "3200/3200 [==============================] - 1s 196us/step - loss: 1.4044 - acc: 0.6053 - val_loss: 1.2195 - val_acc: 0.6800\n",
      "Epoch 514/800\n",
      "3200/3200 [==============================] - 1s 207us/step - loss: 1.3623 - acc: 0.6181 - val_loss: 1.2323 - val_acc: 0.6875\n",
      "Epoch 515/800\n",
      "3200/3200 [==============================] - 1s 199us/step - loss: 1.4236 - acc: 0.5978 - val_loss: 1.2122 - val_acc: 0.6713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 516/800\n",
      "3200/3200 [==============================] - 1s 174us/step - loss: 1.3987 - acc: 0.6116 - val_loss: 1.1943 - val_acc: 0.6825\n",
      "Epoch 517/800\n",
      "3200/3200 [==============================] - 1s 178us/step - loss: 1.3952 - acc: 0.6103 - val_loss: 1.1384 - val_acc: 0.6975\n",
      "Epoch 518/800\n",
      "3200/3200 [==============================] - 1s 195us/step - loss: 1.4140 - acc: 0.5988 - val_loss: 1.2000 - val_acc: 0.6763\n",
      "Epoch 519/800\n",
      "3200/3200 [==============================] - 1s 170us/step - loss: 1.3675 - acc: 0.6191 - val_loss: 1.1925 - val_acc: 0.6950\n",
      "Epoch 520/800\n",
      "3200/3200 [==============================] - 1s 181us/step - loss: 1.3955 - acc: 0.6172 - val_loss: 1.1609 - val_acc: 0.6887\n",
      "Epoch 521/800\n",
      "3200/3200 [==============================] - 1s 177us/step - loss: 1.4057 - acc: 0.6019 - val_loss: 1.1850 - val_acc: 0.7000\n",
      "Epoch 522/800\n",
      "3200/3200 [==============================] - 1s 189us/step - loss: 1.4388 - acc: 0.5925 - val_loss: 1.2010 - val_acc: 0.6925\n",
      "Epoch 523/800\n",
      "3200/3200 [==============================] - 1s 185us/step - loss: 1.3510 - acc: 0.6134 - val_loss: 1.2445 - val_acc: 0.6725\n",
      "Epoch 524/800\n",
      "3200/3200 [==============================] - 1s 246us/step - loss: 1.3906 - acc: 0.6034 - val_loss: 1.1907 - val_acc: 0.6737\n",
      "Epoch 525/800\n",
      "3200/3200 [==============================] - 1s 193us/step - loss: 1.4274 - acc: 0.6047 - val_loss: 1.2376 - val_acc: 0.6813\n",
      "Epoch 526/800\n",
      "3200/3200 [==============================] - 1s 171us/step - loss: 1.3958 - acc: 0.6091 - val_loss: 1.2384 - val_acc: 0.6863\n",
      "Epoch 527/800\n",
      "3200/3200 [==============================] - 1s 181us/step - loss: 1.4129 - acc: 0.5997 - val_loss: 1.2415 - val_acc: 0.6875\n",
      "Epoch 528/800\n",
      "3200/3200 [==============================] - 1s 177us/step - loss: 1.3892 - acc: 0.5988 - val_loss: 1.2105 - val_acc: 0.6937\n",
      "Epoch 529/800\n",
      "3200/3200 [==============================] - 1s 183us/step - loss: 1.3804 - acc: 0.6009 - val_loss: 1.2297 - val_acc: 0.6925\n",
      "Epoch 530/800\n",
      "3200/3200 [==============================] - 1s 175us/step - loss: 1.3866 - acc: 0.6156 - val_loss: 1.1906 - val_acc: 0.7037\n",
      "Epoch 531/800\n",
      "3200/3200 [==============================] - 1s 178us/step - loss: 1.3372 - acc: 0.6112 - val_loss: 1.1833 - val_acc: 0.6987\n",
      "Epoch 532/800\n",
      "3200/3200 [==============================] - 1s 165us/step - loss: 1.3730 - acc: 0.6047 - val_loss: 1.1920 - val_acc: 0.6900\n",
      "Epoch 533/800\n",
      "3200/3200 [==============================] - 1s 188us/step - loss: 1.3789 - acc: 0.6003 - val_loss: 1.1668 - val_acc: 0.6925\n",
      "Epoch 534/800\n",
      "3200/3200 [==============================] - 1s 178us/step - loss: 1.4815 - acc: 0.5906 - val_loss: 1.2676 - val_acc: 0.6562\n",
      "Epoch 535/800\n",
      "3200/3200 [==============================] - 1s 187us/step - loss: 1.3716 - acc: 0.6091 - val_loss: 1.1776 - val_acc: 0.6987\n",
      "Epoch 536/800\n",
      "3200/3200 [==============================] - 1s 183us/step - loss: 1.3995 - acc: 0.6009 - val_loss: 1.2004 - val_acc: 0.6900\n",
      "Epoch 537/800\n",
      "3200/3200 [==============================] - 1s 182us/step - loss: 1.4118 - acc: 0.6006 - val_loss: 1.2106 - val_acc: 0.6887\n",
      "Epoch 538/800\n",
      "3200/3200 [==============================] - 1s 186us/step - loss: 1.3618 - acc: 0.6200 - val_loss: 1.1887 - val_acc: 0.7037\n",
      "Epoch 539/800\n",
      "3200/3200 [==============================] - 1s 174us/step - loss: 1.3772 - acc: 0.6147 - val_loss: 1.1883 - val_acc: 0.6887\n",
      "Epoch 540/800\n",
      "3200/3200 [==============================] - 1s 201us/step - loss: 1.4114 - acc: 0.6084 - val_loss: 1.1944 - val_acc: 0.6887\n",
      "Epoch 541/800\n",
      "3200/3200 [==============================] - 1s 175us/step - loss: 1.3843 - acc: 0.6016 - val_loss: 1.1867 - val_acc: 0.6875\n",
      "Epoch 542/800\n",
      "3200/3200 [==============================] - 1s 192us/step - loss: 1.3664 - acc: 0.6153 - val_loss: 1.2185 - val_acc: 0.6825\n",
      "Epoch 543/800\n",
      "3200/3200 [==============================] - 1s 197us/step - loss: 1.3462 - acc: 0.6178 - val_loss: 1.1814 - val_acc: 0.7037\n",
      "Epoch 544/800\n",
      "3200/3200 [==============================] - 1s 180us/step - loss: 1.3721 - acc: 0.5997 - val_loss: 1.1880 - val_acc: 0.7063\n",
      "Epoch 545/800\n",
      "3200/3200 [==============================] - 1s 191us/step - loss: 1.3778 - acc: 0.6147 - val_loss: 1.1574 - val_acc: 0.6925\n",
      "Epoch 546/800\n",
      "3200/3200 [==============================] - 1s 180us/step - loss: 1.3716 - acc: 0.6031 - val_loss: 1.1796 - val_acc: 0.6900\n",
      "Epoch 547/800\n",
      "3200/3200 [==============================] - 1s 195us/step - loss: 1.3418 - acc: 0.6200 - val_loss: 1.1818 - val_acc: 0.6950\n",
      "Epoch 548/800\n",
      "3200/3200 [==============================] - 1s 185us/step - loss: 1.3224 - acc: 0.6238 - val_loss: 1.1659 - val_acc: 0.6850\n",
      "Epoch 549/800\n",
      "3200/3200 [==============================] - 1s 193us/step - loss: 1.3682 - acc: 0.6109 - val_loss: 1.1747 - val_acc: 0.6925\n",
      "Epoch 550/800\n",
      "3200/3200 [==============================] - 1s 204us/step - loss: 1.4006 - acc: 0.6128 - val_loss: 1.2031 - val_acc: 0.7013\n",
      "Epoch 551/800\n",
      "3200/3200 [==============================] - 1s 281us/step - loss: 1.3893 - acc: 0.6038 - val_loss: 1.1616 - val_acc: 0.6925\n",
      "Epoch 552/800\n",
      "3200/3200 [==============================] - 1s 219us/step - loss: 1.3340 - acc: 0.6322 - val_loss: 1.1789 - val_acc: 0.6925\n",
      "Epoch 553/800\n",
      "3200/3200 [==============================] - 1s 187us/step - loss: 1.3569 - acc: 0.6169 - val_loss: 1.2349 - val_acc: 0.6850\n",
      "Epoch 554/800\n",
      "3200/3200 [==============================] - 1s 188us/step - loss: 1.3321 - acc: 0.6147 - val_loss: 1.1990 - val_acc: 0.6875\n",
      "Epoch 555/800\n",
      "3200/3200 [==============================] - 1s 186us/step - loss: 1.3297 - acc: 0.6306 - val_loss: 1.1987 - val_acc: 0.6950\n",
      "Epoch 556/800\n",
      "3200/3200 [==============================] - 1s 201us/step - loss: 1.3653 - acc: 0.6162 - val_loss: 1.1640 - val_acc: 0.7000\n",
      "Epoch 557/800\n",
      "3200/3200 [==============================] - 1s 199us/step - loss: 1.3512 - acc: 0.6209 - val_loss: 1.1597 - val_acc: 0.6963\n",
      "Epoch 558/800\n",
      "3200/3200 [==============================] - 1s 175us/step - loss: 1.3626 - acc: 0.6228 - val_loss: 1.1859 - val_acc: 0.7013\n",
      "Epoch 559/800\n",
      "3200/3200 [==============================] - 1s 195us/step - loss: 1.3827 - acc: 0.6066 - val_loss: 1.2068 - val_acc: 0.6800\n",
      "Epoch 560/800\n",
      "3200/3200 [==============================] - 1s 182us/step - loss: 1.3972 - acc: 0.6072 - val_loss: 1.1711 - val_acc: 0.7000\n",
      "Epoch 561/800\n",
      "3200/3200 [==============================] - 1s 192us/step - loss: 1.3678 - acc: 0.6178 - val_loss: 1.1280 - val_acc: 0.6987\n",
      "Epoch 562/800\n",
      "3200/3200 [==============================] - 1s 191us/step - loss: 1.3834 - acc: 0.6119 - val_loss: 1.1509 - val_acc: 0.7000\n",
      "Epoch 563/800\n",
      "3200/3200 [==============================] - 1s 196us/step - loss: 1.3341 - acc: 0.6184 - val_loss: 1.1426 - val_acc: 0.7087\n",
      "Epoch 564/800\n",
      "3200/3200 [==============================] - 1s 191us/step - loss: 1.3940 - acc: 0.6094 - val_loss: 1.1786 - val_acc: 0.6863\n",
      "Epoch 565/800\n",
      "3200/3200 [==============================] - 1s 196us/step - loss: 1.3699 - acc: 0.6253 - val_loss: 1.1679 - val_acc: 0.6863\n",
      "Epoch 566/800\n",
      "3200/3200 [==============================] - 1s 185us/step - loss: 1.3933 - acc: 0.6109 - val_loss: 1.1747 - val_acc: 0.6863\n",
      "Epoch 567/800\n",
      "3200/3200 [==============================] - 1s 205us/step - loss: 1.3246 - acc: 0.6272 - val_loss: 1.1511 - val_acc: 0.7100\n",
      "Epoch 568/800\n",
      "3200/3200 [==============================] - 1s 191us/step - loss: 1.2860 - acc: 0.6319 - val_loss: 1.1674 - val_acc: 0.7163\n",
      "Epoch 569/800\n",
      "3200/3200 [==============================] - 1s 198us/step - loss: 1.3133 - acc: 0.6325 - val_loss: 1.1490 - val_acc: 0.7050\n",
      "Epoch 570/800\n",
      "3200/3200 [==============================] - 1s 197us/step - loss: 1.3533 - acc: 0.6256 - val_loss: 1.1459 - val_acc: 0.7037\n",
      "Epoch 571/800\n",
      "3200/3200 [==============================] - 1s 199us/step - loss: 1.3511 - acc: 0.6325 - val_loss: 1.1727 - val_acc: 0.6950\n",
      "Epoch 572/800\n",
      "3200/3200 [==============================] - 1s 186us/step - loss: 1.3092 - acc: 0.6319 - val_loss: 1.1432 - val_acc: 0.7087\n",
      "Epoch 573/800\n",
      "3200/3200 [==============================] - 1s 190us/step - loss: 1.3084 - acc: 0.6209 - val_loss: 1.1594 - val_acc: 0.6913\n",
      "Epoch 574/800\n",
      "3200/3200 [==============================] - 1s 196us/step - loss: 1.3033 - acc: 0.6231 - val_loss: 1.1156 - val_acc: 0.7163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 575/800\n",
      "3200/3200 [==============================] - 1s 173us/step - loss: 1.3197 - acc: 0.6256 - val_loss: 1.1847 - val_acc: 0.7025\n",
      "Epoch 576/800\n",
      "3200/3200 [==============================] - 1s 242us/step - loss: 1.3138 - acc: 0.6231 - val_loss: 1.1374 - val_acc: 0.7000\n",
      "Epoch 577/800\n",
      "3200/3200 [==============================] - 1s 235us/step - loss: 1.2957 - acc: 0.6287 - val_loss: 1.1314 - val_acc: 0.7137\n",
      "Epoch 578/800\n",
      "3200/3200 [==============================] - 1s 174us/step - loss: 1.3562 - acc: 0.6134 - val_loss: 1.1447 - val_acc: 0.7188\n",
      "Epoch 579/800\n",
      "3200/3200 [==============================] - 1s 174us/step - loss: 1.3007 - acc: 0.6372 - val_loss: 1.0968 - val_acc: 0.7225\n",
      "Epoch 580/800\n",
      "3200/3200 [==============================] - 1s 184us/step - loss: 1.3302 - acc: 0.6281 - val_loss: 1.1536 - val_acc: 0.7087\n",
      "Epoch 581/800\n",
      "3200/3200 [==============================] - 1s 179us/step - loss: 1.3656 - acc: 0.6122 - val_loss: 1.1373 - val_acc: 0.7137\n",
      "Epoch 582/800\n",
      "3200/3200 [==============================] - 1s 179us/step - loss: 1.3608 - acc: 0.6184 - val_loss: 1.1471 - val_acc: 0.7087\n",
      "Epoch 583/800\n",
      "3200/3200 [==============================] - 1s 180us/step - loss: 1.3311 - acc: 0.6266 - val_loss: 1.1713 - val_acc: 0.7037\n",
      "Epoch 584/800\n",
      "3200/3200 [==============================] - 1s 184us/step - loss: 1.3272 - acc: 0.6388 - val_loss: 1.1237 - val_acc: 0.7087\n",
      "Epoch 585/800\n",
      "3200/3200 [==============================] - 1s 172us/step - loss: 1.3102 - acc: 0.6228 - val_loss: 1.1738 - val_acc: 0.6963\n",
      "Epoch 586/800\n",
      "3200/3200 [==============================] - 1s 175us/step - loss: 1.3258 - acc: 0.6287 - val_loss: 1.1457 - val_acc: 0.7013\n",
      "Epoch 587/800\n",
      "3200/3200 [==============================] - 1s 172us/step - loss: 1.3888 - acc: 0.6088 - val_loss: 1.1771 - val_acc: 0.6825\n",
      "Epoch 588/800\n",
      "3200/3200 [==============================] - 1s 174us/step - loss: 1.3547 - acc: 0.6144 - val_loss: 1.1350 - val_acc: 0.7087\n",
      "Epoch 589/800\n",
      "3200/3200 [==============================] - 1s 189us/step - loss: 1.3159 - acc: 0.6338 - val_loss: 1.1349 - val_acc: 0.7137\n",
      "Epoch 590/800\n",
      "3200/3200 [==============================] - 1s 178us/step - loss: 1.3437 - acc: 0.6269 - val_loss: 1.1007 - val_acc: 0.7137\n",
      "Epoch 591/800\n",
      "3200/3200 [==============================] - 1s 189us/step - loss: 1.3710 - acc: 0.6228 - val_loss: 1.1352 - val_acc: 0.7063\n",
      "Epoch 592/800\n",
      "3200/3200 [==============================] - 1s 180us/step - loss: 1.3784 - acc: 0.6141 - val_loss: 1.1520 - val_acc: 0.7050\n",
      "Epoch 593/800\n",
      "3200/3200 [==============================] - 1s 183us/step - loss: 1.3412 - acc: 0.6262 - val_loss: 1.0974 - val_acc: 0.7125\n",
      "Epoch 594/800\n",
      "3200/3200 [==============================] - 1s 182us/step - loss: 1.3223 - acc: 0.6300 - val_loss: 1.0457 - val_acc: 0.7163\n",
      "Epoch 595/800\n",
      "3200/3200 [==============================] - 1s 191us/step - loss: 1.2960 - acc: 0.6347 - val_loss: 1.0697 - val_acc: 0.7125\n",
      "Epoch 596/800\n",
      "3200/3200 [==============================] - 1s 186us/step - loss: 1.3383 - acc: 0.6228 - val_loss: 1.1038 - val_acc: 0.7125\n",
      "Epoch 597/800\n",
      "3200/3200 [==============================] - 1s 176us/step - loss: 1.3825 - acc: 0.6084 - val_loss: 1.1000 - val_acc: 0.6937\n",
      "Epoch 598/800\n",
      "3200/3200 [==============================] - 1s 190us/step - loss: 1.3257 - acc: 0.6200 - val_loss: 1.1565 - val_acc: 0.6950\n",
      "Epoch 599/800\n",
      "3200/3200 [==============================] - 1s 181us/step - loss: 1.3589 - acc: 0.6225 - val_loss: 1.1459 - val_acc: 0.6950\n",
      "Epoch 600/800\n",
      "3200/3200 [==============================] - 1s 432us/step - loss: 1.3508 - acc: 0.6262 - val_loss: 1.1517 - val_acc: 0.6837\n",
      "Epoch 601/800\n",
      "3200/3200 [==============================] - 1s 201us/step - loss: 1.3716 - acc: 0.6291 - val_loss: 1.1153 - val_acc: 0.7200\n",
      "Epoch 602/800\n",
      "3200/3200 [==============================] - 1s 268us/step - loss: 1.2878 - acc: 0.6281 - val_loss: 1.1065 - val_acc: 0.7163\n",
      "Epoch 603/800\n",
      "3200/3200 [==============================] - 1s 212us/step - loss: 1.2845 - acc: 0.6381 - val_loss: 1.0661 - val_acc: 0.7300\n",
      "Epoch 604/800\n",
      "3200/3200 [==============================] - 1s 199us/step - loss: 1.3046 - acc: 0.6306 - val_loss: 1.1187 - val_acc: 0.6987\n",
      "Epoch 605/800\n",
      "3200/3200 [==============================] - 1s 183us/step - loss: 1.3754 - acc: 0.6206 - val_loss: 1.1129 - val_acc: 0.7125\n",
      "Epoch 606/800\n",
      "3200/3200 [==============================] - 1s 199us/step - loss: 1.3385 - acc: 0.6225 - val_loss: 1.1118 - val_acc: 0.7050\n",
      "Epoch 607/800\n",
      "3200/3200 [==============================] - 1s 179us/step - loss: 1.3445 - acc: 0.6203 - val_loss: 1.0908 - val_acc: 0.7188\n",
      "Epoch 608/800\n",
      "3200/3200 [==============================] - 1s 208us/step - loss: 1.2916 - acc: 0.6381 - val_loss: 1.1039 - val_acc: 0.7312\n",
      "Epoch 609/800\n",
      "3200/3200 [==============================] - 1s 176us/step - loss: 1.3253 - acc: 0.6316 - val_loss: 1.1156 - val_acc: 0.7087\n",
      "Epoch 610/800\n",
      "3200/3200 [==============================] - 1s 198us/step - loss: 1.3356 - acc: 0.6259 - val_loss: 1.1357 - val_acc: 0.7125\n",
      "Epoch 611/800\n",
      "3200/3200 [==============================] - 1s 197us/step - loss: 1.2915 - acc: 0.6372 - val_loss: 1.1149 - val_acc: 0.7262\n",
      "Epoch 612/800\n",
      "3200/3200 [==============================] - 1s 177us/step - loss: 1.2835 - acc: 0.6328 - val_loss: 1.0995 - val_acc: 0.7050\n",
      "Epoch 613/800\n",
      "3200/3200 [==============================] - 1s 203us/step - loss: 1.3137 - acc: 0.6303 - val_loss: 1.1696 - val_acc: 0.6975\n",
      "Epoch 614/800\n",
      "3200/3200 [==============================] - 1s 182us/step - loss: 1.3396 - acc: 0.6238 - val_loss: 1.1044 - val_acc: 0.7225\n",
      "Epoch 615/800\n",
      "3200/3200 [==============================] - 1s 197us/step - loss: 1.3032 - acc: 0.6284 - val_loss: 1.0907 - val_acc: 0.7125\n",
      "Epoch 616/800\n",
      "3200/3200 [==============================] - 1s 185us/step - loss: 1.2971 - acc: 0.6231 - val_loss: 1.0431 - val_acc: 0.7262\n",
      "Epoch 617/800\n",
      "3200/3200 [==============================] - 1s 225us/step - loss: 1.3036 - acc: 0.6350 - val_loss: 1.1309 - val_acc: 0.6987\n",
      "Epoch 618/800\n",
      "3200/3200 [==============================] - 1s 371us/step - loss: 1.3375 - acc: 0.6212 - val_loss: 1.1188 - val_acc: 0.7113\n",
      "Epoch 619/800\n",
      "3200/3200 [==============================] - 1s 370us/step - loss: 1.3279 - acc: 0.6328 - val_loss: 1.0873 - val_acc: 0.7087\n",
      "Epoch 620/800\n",
      "3200/3200 [==============================] - 1s 404us/step - loss: 1.3443 - acc: 0.6338 - val_loss: 1.1413 - val_acc: 0.7150\n",
      "Epoch 621/800\n",
      "3200/3200 [==============================] - 1s 398us/step - loss: 1.3272 - acc: 0.6319 - val_loss: 1.0886 - val_acc: 0.7137\n",
      "Epoch 622/800\n",
      "3200/3200 [==============================] - 1s 246us/step - loss: 1.2982 - acc: 0.6256 - val_loss: 1.0871 - val_acc: 0.7137\n",
      "Epoch 623/800\n",
      "3200/3200 [==============================] - 1s 288us/step - loss: 1.2747 - acc: 0.6466 - val_loss: 1.1281 - val_acc: 0.7163\n",
      "Epoch 624/800\n",
      "3200/3200 [==============================] - 1s 228us/step - loss: 1.3342 - acc: 0.6403 - val_loss: 1.1119 - val_acc: 0.7087\n",
      "Epoch 625/800\n",
      "3200/3200 [==============================] - 1s 222us/step - loss: 1.2763 - acc: 0.6469 - val_loss: 1.0949 - val_acc: 0.7150\n",
      "Epoch 626/800\n",
      "3200/3200 [==============================] - 1s 194us/step - loss: 1.2933 - acc: 0.6325 - val_loss: 1.0961 - val_acc: 0.7212\n",
      "Epoch 627/800\n",
      "3200/3200 [==============================] - 1s 204us/step - loss: 1.3375 - acc: 0.6412 - val_loss: 1.0612 - val_acc: 0.7212\n",
      "Epoch 628/800\n",
      "3200/3200 [==============================] - 1s 202us/step - loss: 1.3473 - acc: 0.6287 - val_loss: 1.0722 - val_acc: 0.7125\n",
      "Epoch 629/800\n",
      "3200/3200 [==============================] - 1s 211us/step - loss: 1.2665 - acc: 0.6469 - val_loss: 1.0584 - val_acc: 0.7200\n",
      "Epoch 630/800\n",
      "3200/3200 [==============================] - 1s 218us/step - loss: 1.2541 - acc: 0.6494 - val_loss: 1.0989 - val_acc: 0.7037\n",
      "Epoch 631/800\n",
      "3200/3200 [==============================] - 1s 186us/step - loss: 1.3065 - acc: 0.6400 - val_loss: 1.0602 - val_acc: 0.7050\n",
      "Epoch 632/800\n",
      "3200/3200 [==============================] - 1s 226us/step - loss: 1.2883 - acc: 0.6388 - val_loss: 1.1073 - val_acc: 0.7137\n",
      "Epoch 633/800\n",
      "3200/3200 [==============================] - 1s 224us/step - loss: 1.3416 - acc: 0.6253 - val_loss: 1.0363 - val_acc: 0.7163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 634/800\n",
      "3200/3200 [==============================] - 1s 183us/step - loss: 1.2495 - acc: 0.6488 - val_loss: 1.0826 - val_acc: 0.7125\n",
      "Epoch 635/800\n",
      "3200/3200 [==============================] - 1s 177us/step - loss: 1.3172 - acc: 0.6431 - val_loss: 1.1239 - val_acc: 0.7025\n",
      "Epoch 636/800\n",
      "3200/3200 [==============================] - 1s 186us/step - loss: 1.3283 - acc: 0.6269 - val_loss: 1.0856 - val_acc: 0.7212\n",
      "Epoch 637/800\n",
      "3200/3200 [==============================] - 1s 169us/step - loss: 1.2871 - acc: 0.6422 - val_loss: 1.1417 - val_acc: 0.6937\n",
      "Epoch 638/800\n",
      "3200/3200 [==============================] - 1s 180us/step - loss: 1.3004 - acc: 0.6428 - val_loss: 1.0724 - val_acc: 0.7238\n",
      "Epoch 639/800\n",
      "3200/3200 [==============================] - 1s 172us/step - loss: 1.3256 - acc: 0.6419 - val_loss: 1.0534 - val_acc: 0.7188\n",
      "Epoch 640/800\n",
      "3200/3200 [==============================] - 1s 192us/step - loss: 1.3252 - acc: 0.6428 - val_loss: 1.0577 - val_acc: 0.7037\n",
      "Epoch 641/800\n",
      "3200/3200 [==============================] - 1s 167us/step - loss: 1.2764 - acc: 0.6353 - val_loss: 1.0842 - val_acc: 0.7175\n",
      "Epoch 642/800\n",
      "3200/3200 [==============================] - 1s 186us/step - loss: 1.2846 - acc: 0.6375 - val_loss: 1.0711 - val_acc: 0.7175\n",
      "Epoch 643/800\n",
      "3200/3200 [==============================] - 1s 169us/step - loss: 1.2530 - acc: 0.6500 - val_loss: 1.1132 - val_acc: 0.7100\n",
      "Epoch 644/800\n",
      "3200/3200 [==============================] - 1s 186us/step - loss: 1.2763 - acc: 0.6391 - val_loss: 1.0694 - val_acc: 0.7325\n",
      "Epoch 645/800\n",
      "3200/3200 [==============================] - ETA: 0s - loss: 1.2593 - acc: 0.645 - 1s 182us/step - loss: 1.2566 - acc: 0.6444 - val_loss: 1.0817 - val_acc: 0.7188\n",
      "Epoch 646/800\n",
      "3200/3200 [==============================] - 1s 173us/step - loss: 1.2684 - acc: 0.6437 - val_loss: 1.0841 - val_acc: 0.7100\n",
      "Epoch 647/800\n",
      "3200/3200 [==============================] - 1s 190us/step - loss: 1.3324 - acc: 0.6491 - val_loss: 1.1209 - val_acc: 0.7037\n",
      "Epoch 648/800\n",
      "3200/3200 [==============================] - 1s 239us/step - loss: 1.3782 - acc: 0.6266 - val_loss: 1.0834 - val_acc: 0.7137\n",
      "Epoch 649/800\n",
      "3200/3200 [==============================] - 1s 233us/step - loss: 1.3289 - acc: 0.6328 - val_loss: 1.1077 - val_acc: 0.7212\n",
      "Epoch 650/800\n",
      "3200/3200 [==============================] - 1s 183us/step - loss: 1.3529 - acc: 0.6259 - val_loss: 1.0969 - val_acc: 0.7137\n",
      "Epoch 651/800\n",
      "3200/3200 [==============================] - 1s 188us/step - loss: 1.3401 - acc: 0.6250 - val_loss: 1.0883 - val_acc: 0.7238\n",
      "Epoch 652/800\n",
      "3200/3200 [==============================] - ETA: 0s - loss: 1.2552 - acc: 0.645 - 1s 182us/step - loss: 1.2510 - acc: 0.6478 - val_loss: 1.0978 - val_acc: 0.7225\n",
      "Epoch 653/800\n",
      "3200/3200 [==============================] - 1s 226us/step - loss: 1.3051 - acc: 0.6331 - val_loss: 1.0618 - val_acc: 0.7262\n",
      "Epoch 654/800\n",
      "3200/3200 [==============================] - 1s 192us/step - loss: 1.2547 - acc: 0.6409 - val_loss: 1.0911 - val_acc: 0.7125\n",
      "Epoch 655/800\n",
      "3200/3200 [==============================] - 1s 257us/step - loss: 1.3103 - acc: 0.6472 - val_loss: 1.1094 - val_acc: 0.7175\n",
      "Epoch 656/800\n",
      "3200/3200 [==============================] - 1s 408us/step - loss: 1.3511 - acc: 0.6300 - val_loss: 1.1389 - val_acc: 0.7013\n",
      "Epoch 657/800\n",
      "3200/3200 [==============================] - 1s 328us/step - loss: 1.2907 - acc: 0.6312 - val_loss: 1.0980 - val_acc: 0.7262\n",
      "Epoch 658/800\n",
      "3200/3200 [==============================] - 1s 231us/step - loss: 1.3145 - acc: 0.6366 - val_loss: 1.1353 - val_acc: 0.7225\n",
      "Epoch 659/800\n",
      "3200/3200 [==============================] - 1s 276us/step - loss: 1.3251 - acc: 0.6319 - val_loss: 1.0950 - val_acc: 0.7175\n",
      "Epoch 660/800\n",
      "3200/3200 [==============================] - 1s 298us/step - loss: 1.2534 - acc: 0.6472 - val_loss: 1.0865 - val_acc: 0.7163\n",
      "Epoch 661/800\n",
      "3200/3200 [==============================] - 1s 252us/step - loss: 1.3020 - acc: 0.6231 - val_loss: 1.1373 - val_acc: 0.7087\n",
      "Epoch 662/800\n",
      "3200/3200 [==============================] - 1s 268us/step - loss: 1.3287 - acc: 0.6372 - val_loss: 1.0847 - val_acc: 0.7238\n",
      "Epoch 663/800\n",
      "3200/3200 [==============================] - 1s 280us/step - loss: 1.2874 - acc: 0.6422 - val_loss: 1.1099 - val_acc: 0.7212\n",
      "Epoch 664/800\n",
      "3200/3200 [==============================] - 1s 249us/step - loss: 1.2535 - acc: 0.6469 - val_loss: 1.0852 - val_acc: 0.7262\n",
      "Epoch 665/800\n",
      "3200/3200 [==============================] - 1s 230us/step - loss: 1.2773 - acc: 0.6516 - val_loss: 1.0322 - val_acc: 0.7262\n",
      "Epoch 666/800\n",
      "3200/3200 [==============================] - 1s 232us/step - loss: 1.2541 - acc: 0.6488 - val_loss: 1.1214 - val_acc: 0.6963\n",
      "Epoch 667/800\n",
      "3200/3200 [==============================] - 1s 219us/step - loss: 1.2832 - acc: 0.6372 - val_loss: 1.0790 - val_acc: 0.7125\n",
      "Epoch 668/800\n",
      "3200/3200 [==============================] - 1s 217us/step - loss: 1.2906 - acc: 0.6384 - val_loss: 1.1123 - val_acc: 0.7087\n",
      "Epoch 669/800\n",
      "3200/3200 [==============================] - 1s 212us/step - loss: 1.2922 - acc: 0.6394 - val_loss: 1.1212 - val_acc: 0.7075\n",
      "Epoch 670/800\n",
      "3200/3200 [==============================] - 1s 266us/step - loss: 1.2411 - acc: 0.6584 - val_loss: 1.0648 - val_acc: 0.7325\n",
      "Epoch 671/800\n",
      "3200/3200 [==============================] - 1s 311us/step - loss: 1.3953 - acc: 0.6281 - val_loss: 1.0896 - val_acc: 0.7063\n",
      "Epoch 672/800\n",
      "3200/3200 [==============================] - 1s 276us/step - loss: 1.2750 - acc: 0.6397 - val_loss: 1.0649 - val_acc: 0.7312\n",
      "Epoch 673/800\n",
      "3200/3200 [==============================] - 1s 226us/step - loss: 1.3167 - acc: 0.6416 - val_loss: 1.1026 - val_acc: 0.7137\n",
      "Epoch 674/800\n",
      "3200/3200 [==============================] - 1s 249us/step - loss: 1.3474 - acc: 0.6312 - val_loss: 1.0636 - val_acc: 0.7300\n",
      "Epoch 675/800\n",
      "3200/3200 [==============================] - 1s 201us/step - loss: 1.2886 - acc: 0.6353 - val_loss: 1.0960 - val_acc: 0.7262\n",
      "Epoch 676/800\n",
      "3200/3200 [==============================] - 1s 238us/step - loss: 1.2869 - acc: 0.6475 - val_loss: 1.1161 - val_acc: 0.7200\n",
      "Epoch 677/800\n",
      "3200/3200 [==============================] - 1s 185us/step - loss: 1.3178 - acc: 0.6306 - val_loss: 1.1514 - val_acc: 0.7188\n",
      "Epoch 678/800\n",
      "3200/3200 [==============================] - 1s 190us/step - loss: 1.2438 - acc: 0.6459 - val_loss: 1.0840 - val_acc: 0.7262\n",
      "Epoch 679/800\n",
      "3200/3200 [==============================] - 1s 190us/step - loss: 1.3094 - acc: 0.6291 - val_loss: 1.0275 - val_acc: 0.7200\n",
      "Epoch 680/800\n",
      "3200/3200 [==============================] - 1s 192us/step - loss: 1.2548 - acc: 0.6597 - val_loss: 1.0993 - val_acc: 0.7137\n",
      "Epoch 681/800\n",
      "3200/3200 [==============================] - 1s 191us/step - loss: 1.2643 - acc: 0.6556 - val_loss: 1.0687 - val_acc: 0.7312\n",
      "Epoch 682/800\n",
      "3200/3200 [==============================] - 1s 196us/step - loss: 1.2468 - acc: 0.6428 - val_loss: 1.0562 - val_acc: 0.7288\n",
      "Epoch 683/800\n",
      "3200/3200 [==============================] - ETA: 0s - loss: 1.2507 - acc: 0.658 - 1s 185us/step - loss: 1.2768 - acc: 0.6534 - val_loss: 1.0376 - val_acc: 0.7300\n",
      "Epoch 684/800\n",
      "3200/3200 [==============================] - 1s 193us/step - loss: 1.3206 - acc: 0.6306 - val_loss: 1.0723 - val_acc: 0.7300\n",
      "Epoch 685/800\n",
      "3200/3200 [==============================] - ETA: 0s - loss: 1.2842 - acc: 0.652 - 1s 196us/step - loss: 1.2778 - acc: 0.6525 - val_loss: 1.0274 - val_acc: 0.7325\n",
      "Epoch 686/800\n",
      "3200/3200 [==============================] - 1s 186us/step - loss: 1.2854 - acc: 0.6462 - val_loss: 1.0543 - val_acc: 0.7350\n",
      "Epoch 687/800\n",
      "3200/3200 [==============================] - 1s 206us/step - loss: 1.2375 - acc: 0.6534 - val_loss: 1.0461 - val_acc: 0.7275\n",
      "Epoch 688/800\n",
      "3200/3200 [==============================] - 1s 187us/step - loss: 1.2409 - acc: 0.6572 - val_loss: 1.0473 - val_acc: 0.7400\n",
      "Epoch 689/800\n",
      "3200/3200 [==============================] - 1s 299us/step - loss: 1.2393 - acc: 0.6603 - val_loss: 1.0211 - val_acc: 0.7250\n",
      "Epoch 690/800\n",
      "3200/3200 [==============================] - 1s 457us/step - loss: 1.2165 - acc: 0.6497 - val_loss: 1.0245 - val_acc: 0.7362\n",
      "Epoch 691/800\n",
      "3200/3200 [==============================] - 1s 286us/step - loss: 1.2666 - acc: 0.6506 - val_loss: 1.0590 - val_acc: 0.7275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 692/800\n",
      "3200/3200 [==============================] - 1s 183us/step - loss: 1.3036 - acc: 0.6400 - val_loss: 1.0789 - val_acc: 0.7163\n",
      "Epoch 693/800\n",
      "3200/3200 [==============================] - 1s 198us/step - loss: 1.2933 - acc: 0.6447 - val_loss: 1.0603 - val_acc: 0.7362\n",
      "Epoch 694/800\n",
      "3200/3200 [==============================] - 1s 231us/step - loss: 1.2902 - acc: 0.6400 - val_loss: 1.0588 - val_acc: 0.7275\n",
      "Epoch 695/800\n",
      "3200/3200 [==============================] - 1s 196us/step - loss: 1.2536 - acc: 0.6550 - val_loss: 0.9993 - val_acc: 0.7462\n",
      "Epoch 696/800\n",
      "3200/3200 [==============================] - 1s 283us/step - loss: 1.2515 - acc: 0.6534 - val_loss: 1.0199 - val_acc: 0.7438\n",
      "Epoch 697/800\n",
      "3200/3200 [==============================] - 1s 186us/step - loss: 1.2132 - acc: 0.6681 - val_loss: 1.0253 - val_acc: 0.7462\n",
      "Epoch 698/800\n",
      "3200/3200 [==============================] - 1s 191us/step - loss: 1.2698 - acc: 0.6509 - val_loss: 1.0483 - val_acc: 0.7325\n",
      "Epoch 699/800\n",
      "3200/3200 [==============================] - 1s 177us/step - loss: 1.2864 - acc: 0.6494 - val_loss: 1.0316 - val_acc: 0.7375\n",
      "Epoch 700/800\n",
      "3200/3200 [==============================] - 1s 213us/step - loss: 1.2501 - acc: 0.6506 - val_loss: 1.0120 - val_acc: 0.7512\n",
      "Epoch 701/800\n",
      "3200/3200 [==============================] - 1s 199us/step - loss: 1.1881 - acc: 0.6597 - val_loss: 1.0411 - val_acc: 0.7350\n",
      "Epoch 702/800\n",
      "3200/3200 [==============================] - 1s 190us/step - loss: 1.2915 - acc: 0.6409 - val_loss: 1.0402 - val_acc: 0.7212\n",
      "Epoch 703/800\n",
      "3200/3200 [==============================] - 1s 179us/step - loss: 1.2577 - acc: 0.6497 - val_loss: 1.0143 - val_acc: 0.7412\n",
      "Epoch 704/800\n",
      "3200/3200 [==============================] - 1s 180us/step - loss: 1.2636 - acc: 0.6384 - val_loss: 1.0334 - val_acc: 0.7362\n",
      "Epoch 705/800\n",
      "3200/3200 [==============================] - 1s 252us/step - loss: 1.2708 - acc: 0.6522 - val_loss: 1.0611 - val_acc: 0.7338\n",
      "Epoch 706/800\n",
      "3200/3200 [==============================] - 1s 171us/step - loss: 1.2163 - acc: 0.6575 - val_loss: 1.0697 - val_acc: 0.7262\n",
      "Epoch 707/800\n",
      "3200/3200 [==============================] - 1s 214us/step - loss: 1.2670 - acc: 0.6566 - val_loss: 1.0645 - val_acc: 0.7163\n",
      "Epoch 708/800\n",
      "3200/3200 [==============================] - 1s 218us/step - loss: 1.2442 - acc: 0.6406 - val_loss: 1.0492 - val_acc: 0.7338\n",
      "Epoch 709/800\n",
      "3200/3200 [==============================] - 1s 231us/step - loss: 1.2942 - acc: 0.6497 - val_loss: 1.0897 - val_acc: 0.7200\n",
      "Epoch 710/800\n",
      "3200/3200 [==============================] - 1s 169us/step - loss: 1.2570 - acc: 0.6472 - val_loss: 1.0417 - val_acc: 0.7300\n",
      "Epoch 711/800\n",
      "3200/3200 [==============================] - 1s 175us/step - loss: 1.2925 - acc: 0.6447 - val_loss: 1.0683 - val_acc: 0.7275\n",
      "Epoch 712/800\n",
      "3200/3200 [==============================] - 1s 200us/step - loss: 1.2748 - acc: 0.6459 - val_loss: 1.0684 - val_acc: 0.7200\n",
      "Epoch 713/800\n",
      "3200/3200 [==============================] - 1s 179us/step - loss: 1.2579 - acc: 0.6603 - val_loss: 1.0391 - val_acc: 0.7388\n",
      "Epoch 714/800\n",
      "3200/3200 [==============================] - 1s 257us/step - loss: 1.2538 - acc: 0.6525 - val_loss: 1.0126 - val_acc: 0.7425\n",
      "Epoch 715/800\n",
      "3200/3200 [==============================] - 1s 239us/step - loss: 1.2746 - acc: 0.6519 - val_loss: 1.0755 - val_acc: 0.7350\n",
      "Epoch 716/800\n",
      "3200/3200 [==============================] - 1s 170us/step - loss: 1.3206 - acc: 0.6406 - val_loss: 1.0415 - val_acc: 0.7288\n",
      "Epoch 717/800\n",
      "3200/3200 [==============================] - 1s 175us/step - loss: 1.2719 - acc: 0.6441 - val_loss: 1.0498 - val_acc: 0.7375\n",
      "Epoch 718/800\n",
      "3200/3200 [==============================] - 1s 184us/step - loss: 1.2868 - acc: 0.6450 - val_loss: 1.0368 - val_acc: 0.7538\n",
      "Epoch 719/800\n",
      "3200/3200 [==============================] - 1s 192us/step - loss: 1.3129 - acc: 0.6328 - val_loss: 1.0736 - val_acc: 0.7275\n",
      "Epoch 720/800\n",
      "3200/3200 [==============================] - 1s 232us/step - loss: 1.2952 - acc: 0.6409 - val_loss: 1.0413 - val_acc: 0.7450\n",
      "Epoch 721/800\n",
      "3200/3200 [==============================] - 1s 228us/step - loss: 1.3189 - acc: 0.6462 - val_loss: 1.0429 - val_acc: 0.7288\n",
      "Epoch 722/800\n",
      "3200/3200 [==============================] - 1s 312us/step - loss: 1.3226 - acc: 0.6344 - val_loss: 1.0490 - val_acc: 0.7238\n",
      "Epoch 723/800\n",
      "3200/3200 [==============================] - 1s 458us/step - loss: 1.2338 - acc: 0.6519 - val_loss: 1.0424 - val_acc: 0.7300\n",
      "Epoch 724/800\n",
      "3200/3200 [==============================] - 1s 199us/step - loss: 1.2672 - acc: 0.6562 - val_loss: 1.1124 - val_acc: 0.7037\n",
      "Epoch 725/800\n",
      "3200/3200 [==============================] - 1s 194us/step - loss: 1.2533 - acc: 0.6522 - val_loss: 1.0279 - val_acc: 0.7400\n",
      "Epoch 726/800\n",
      "3200/3200 [==============================] - 1s 232us/step - loss: 1.2679 - acc: 0.6456 - val_loss: 0.9956 - val_acc: 0.7400\n",
      "Epoch 727/800\n",
      "3200/3200 [==============================] - 1s 218us/step - loss: 1.2170 - acc: 0.6566 - val_loss: 1.0764 - val_acc: 0.7288\n",
      "Epoch 728/800\n",
      "3200/3200 [==============================] - 1s 230us/step - loss: 1.2667 - acc: 0.6503 - val_loss: 1.0649 - val_acc: 0.7325\n",
      "Epoch 729/800\n",
      "3200/3200 [==============================] - 1s 249us/step - loss: 1.2803 - acc: 0.6391 - val_loss: 1.0354 - val_acc: 0.7375\n",
      "Epoch 730/800\n",
      "3200/3200 [==============================] - 1s 261us/step - loss: 1.2653 - acc: 0.6497 - val_loss: 1.0586 - val_acc: 0.7275\n",
      "Epoch 731/800\n",
      "3200/3200 [==============================] - 1s 257us/step - loss: 1.2587 - acc: 0.6509 - val_loss: 1.0314 - val_acc: 0.7325\n",
      "Epoch 732/800\n",
      "3200/3200 [==============================] - 1s 204us/step - loss: 1.2605 - acc: 0.6512 - val_loss: 1.0332 - val_acc: 0.7412\n",
      "Epoch 733/800\n",
      "3200/3200 [==============================] - 0s 146us/step - loss: 1.2678 - acc: 0.6462 - val_loss: 1.0910 - val_acc: 0.7188\n",
      "Epoch 734/800\n",
      "3200/3200 [==============================] - 0s 156us/step - loss: 1.2202 - acc: 0.6591 - val_loss: 1.0806 - val_acc: 0.7238\n",
      "Epoch 735/800\n",
      "3200/3200 [==============================] - 1s 176us/step - loss: 1.2654 - acc: 0.6472 - val_loss: 1.1125 - val_acc: 0.7175\n",
      "Epoch 736/800\n",
      "3200/3200 [==============================] - 1s 181us/step - loss: 1.2709 - acc: 0.6425 - val_loss: 1.0614 - val_acc: 0.7388\n",
      "Epoch 737/800\n",
      "3200/3200 [==============================] - 1s 184us/step - loss: 1.2369 - acc: 0.6572 - val_loss: 1.0382 - val_acc: 0.7400\n",
      "Epoch 738/800\n",
      "3200/3200 [==============================] - 1s 159us/step - loss: 1.2194 - acc: 0.6566 - val_loss: 1.0591 - val_acc: 0.7325\n",
      "Epoch 739/800\n",
      "3200/3200 [==============================] - 1s 159us/step - loss: 1.2450 - acc: 0.6516 - val_loss: 1.0035 - val_acc: 0.7325\n",
      "Epoch 740/800\n",
      "3200/3200 [==============================] - 0s 145us/step - loss: 1.2250 - acc: 0.6594 - val_loss: 1.0252 - val_acc: 0.7262\n",
      "Epoch 741/800\n",
      "3200/3200 [==============================] - 0s 149us/step - loss: 1.2250 - acc: 0.6584 - val_loss: 1.0076 - val_acc: 0.7525\n",
      "Epoch 742/800\n",
      "3200/3200 [==============================] - 0s 145us/step - loss: 1.2616 - acc: 0.6428 - val_loss: 1.0163 - val_acc: 0.7462\n",
      "Epoch 743/800\n",
      "3200/3200 [==============================] - 0s 149us/step - loss: 1.2557 - acc: 0.6534 - val_loss: 1.0347 - val_acc: 0.7412\n",
      "Epoch 744/800\n",
      "3200/3200 [==============================] - 0s 140us/step - loss: 1.2751 - acc: 0.6488 - val_loss: 1.0629 - val_acc: 0.7275\n",
      "Epoch 745/800\n",
      "3200/3200 [==============================] - 0s 151us/step - loss: 1.2465 - acc: 0.6478 - val_loss: 0.9993 - val_acc: 0.7362\n",
      "Epoch 746/800\n",
      "3200/3200 [==============================] - 1s 184us/step - loss: 1.2740 - acc: 0.6522 - val_loss: 1.0394 - val_acc: 0.7325\n",
      "Epoch 747/800\n",
      "3200/3200 [==============================] - 1s 170us/step - loss: 1.2673 - acc: 0.6531 - val_loss: 1.0435 - val_acc: 0.7362\n",
      "Epoch 748/800\n",
      "3200/3200 [==============================] - 1s 163us/step - loss: 1.2676 - acc: 0.6500 - val_loss: 1.0533 - val_acc: 0.7312\n",
      "Epoch 749/800\n",
      "3200/3200 [==============================] - 1s 197us/step - loss: 1.2474 - acc: 0.6622 - val_loss: 1.0387 - val_acc: 0.7425\n",
      "Epoch 750/800\n",
      "3200/3200 [==============================] - 1s 182us/step - loss: 1.2489 - acc: 0.6641 - val_loss: 1.0661 - val_acc: 0.7312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 751/800\n",
      "3200/3200 [==============================] - 0s 143us/step - loss: 1.2082 - acc: 0.6609 - val_loss: 1.0565 - val_acc: 0.7312\n",
      "Epoch 752/800\n",
      "3200/3200 [==============================] - 1s 192us/step - loss: 1.2351 - acc: 0.6547 - val_loss: 1.0730 - val_acc: 0.7275\n",
      "Epoch 753/800\n",
      "3200/3200 [==============================] - 1s 190us/step - loss: 1.2825 - acc: 0.6484 - val_loss: 1.0609 - val_acc: 0.7412\n",
      "Epoch 754/800\n",
      "3200/3200 [==============================] - 1s 180us/step - loss: 1.2492 - acc: 0.6625 - val_loss: 1.0529 - val_acc: 0.7400\n",
      "Epoch 755/800\n",
      "3200/3200 [==============================] - 1s 164us/step - loss: 1.2346 - acc: 0.6497 - val_loss: 1.0516 - val_acc: 0.7400\n",
      "Epoch 756/800\n",
      "3200/3200 [==============================] - 0s 150us/step - loss: 1.2280 - acc: 0.6691 - val_loss: 1.0285 - val_acc: 0.7388\n",
      "Epoch 757/800\n",
      "3200/3200 [==============================] - 1s 179us/step - loss: 1.2397 - acc: 0.6587 - val_loss: 1.0343 - val_acc: 0.7538\n",
      "Epoch 758/800\n",
      "3200/3200 [==============================] - 0s 156us/step - loss: 1.2545 - acc: 0.6531 - val_loss: 1.0701 - val_acc: 0.7362\n",
      "Epoch 759/800\n",
      "3200/3200 [==============================] - 0s 142us/step - loss: 1.2344 - acc: 0.6456 - val_loss: 1.0872 - val_acc: 0.7338\n",
      "Epoch 760/800\n",
      "3200/3200 [==============================] - 1s 167us/step - loss: 1.2726 - acc: 0.6538 - val_loss: 1.1118 - val_acc: 0.7137\n",
      "Epoch 761/800\n",
      "3200/3200 [==============================] - 1s 165us/step - loss: 1.3395 - acc: 0.6419 - val_loss: 1.0789 - val_acc: 0.7250\n",
      "Epoch 762/800\n",
      "3200/3200 [==============================] - 0s 141us/step - loss: 1.2854 - acc: 0.6381 - val_loss: 1.0608 - val_acc: 0.7362\n",
      "Epoch 763/800\n",
      "3200/3200 [==============================] - 0s 147us/step - loss: 1.2693 - acc: 0.6522 - val_loss: 1.0523 - val_acc: 0.7250\n",
      "Epoch 764/800\n",
      "3200/3200 [==============================] - 1s 224us/step - loss: 1.2553 - acc: 0.6578 - val_loss: 1.0321 - val_acc: 0.7362\n",
      "Epoch 765/800\n",
      "3200/3200 [==============================] - 1s 260us/step - loss: 1.2405 - acc: 0.6525 - val_loss: 1.0761 - val_acc: 0.7275\n",
      "Epoch 766/800\n",
      "3200/3200 [==============================] - 1s 200us/step - loss: 1.2491 - acc: 0.6622 - val_loss: 1.0515 - val_acc: 0.7238\n",
      "Epoch 767/800\n",
      "3200/3200 [==============================] - 1s 163us/step - loss: 1.2344 - acc: 0.6597 - val_loss: 1.0500 - val_acc: 0.7350\n",
      "Epoch 768/800\n",
      "3200/3200 [==============================] - 0s 147us/step - loss: 1.2497 - acc: 0.6500 - val_loss: 1.0211 - val_acc: 0.7412\n",
      "Epoch 769/800\n",
      "3200/3200 [==============================] - 1s 181us/step - loss: 1.2511 - acc: 0.6528 - val_loss: 1.0216 - val_acc: 0.7425\n",
      "Epoch 770/800\n",
      "3200/3200 [==============================] - 1s 164us/step - loss: 1.2757 - acc: 0.6494 - val_loss: 0.9996 - val_acc: 0.7575\n",
      "Epoch 771/800\n",
      "3200/3200 [==============================] - 1s 160us/step - loss: 1.2490 - acc: 0.6637 - val_loss: 1.0387 - val_acc: 0.7438\n",
      "Epoch 772/800\n",
      "3200/3200 [==============================] - 0s 153us/step - loss: 1.2254 - acc: 0.6606 - val_loss: 1.0399 - val_acc: 0.7550\n",
      "Epoch 773/800\n",
      "3200/3200 [==============================] - 0s 135us/step - loss: 1.2599 - acc: 0.6491 - val_loss: 1.0757 - val_acc: 0.7325\n",
      "Epoch 774/800\n",
      "3200/3200 [==============================] - 1s 165us/step - loss: 1.2452 - acc: 0.6663 - val_loss: 1.0887 - val_acc: 0.7325\n",
      "Epoch 775/800\n",
      "3200/3200 [==============================] - 0s 146us/step - loss: 1.2584 - acc: 0.6491 - val_loss: 1.0343 - val_acc: 0.7462\n",
      "Epoch 776/800\n",
      "3200/3200 [==============================] - 1s 173us/step - loss: 1.2374 - acc: 0.6650 - val_loss: 1.0543 - val_acc: 0.7375\n",
      "Epoch 777/800\n",
      "3200/3200 [==============================] - 1s 180us/step - loss: 1.3177 - acc: 0.6409 - val_loss: 1.0406 - val_acc: 0.7525\n",
      "Epoch 778/800\n",
      "3200/3200 [==============================] - 1s 172us/step - loss: 1.2739 - acc: 0.6522 - val_loss: 1.0149 - val_acc: 0.7488\n",
      "Epoch 779/800\n",
      "3200/3200 [==============================] - 0s 154us/step - loss: 1.2161 - acc: 0.6566 - val_loss: 1.0212 - val_acc: 0.7325\n",
      "Epoch 780/800\n",
      "3200/3200 [==============================] - 0s 154us/step - loss: 1.2704 - acc: 0.6503 - val_loss: 1.0207 - val_acc: 0.7512\n",
      "Epoch 781/800\n",
      "3200/3200 [==============================] - 1s 247us/step - loss: 1.2462 - acc: 0.6547 - val_loss: 0.9902 - val_acc: 0.7612\n",
      "Epoch 782/800\n",
      "3200/3200 [==============================] - 1s 347us/step - loss: 1.1807 - acc: 0.6784 - val_loss: 1.0178 - val_acc: 0.7512\n",
      "Epoch 783/800\n",
      "3200/3200 [==============================] - 0s 151us/step - loss: 1.2408 - acc: 0.6634 - val_loss: 1.0247 - val_acc: 0.7638\n",
      "Epoch 784/800\n",
      "3200/3200 [==============================] - 1s 196us/step - loss: 1.2456 - acc: 0.6547 - val_loss: 1.0195 - val_acc: 0.7550\n",
      "Epoch 785/800\n",
      "3200/3200 [==============================] - 1s 158us/step - loss: 1.2212 - acc: 0.6619 - val_loss: 1.0029 - val_acc: 0.7400\n",
      "Epoch 786/800\n",
      "3200/3200 [==============================] - 0s 155us/step - loss: 1.2123 - acc: 0.6647 - val_loss: 0.9971 - val_acc: 0.7550\n",
      "Epoch 787/800\n",
      "3200/3200 [==============================] - 1s 180us/step - loss: 1.1998 - acc: 0.6731 - val_loss: 1.0508 - val_acc: 0.7338\n",
      "Epoch 788/800\n",
      "3200/3200 [==============================] - 1s 160us/step - loss: 1.2812 - acc: 0.6522 - val_loss: 1.0270 - val_acc: 0.7475\n",
      "Epoch 789/800\n",
      "3200/3200 [==============================] - 1s 260us/step - loss: 1.2333 - acc: 0.6547 - val_loss: 1.0292 - val_acc: 0.7400\n",
      "Epoch 790/800\n",
      "3200/3200 [==============================] - 1s 306us/step - loss: 1.2270 - acc: 0.6578 - val_loss: 1.0700 - val_acc: 0.7412\n",
      "Epoch 791/800\n",
      "3200/3200 [==============================] - 1s 167us/step - loss: 1.2712 - acc: 0.6541 - val_loss: 1.0423 - val_acc: 0.7325\n",
      "Epoch 792/800\n",
      "3200/3200 [==============================] - 1s 177us/step - loss: 1.2852 - acc: 0.6472 - val_loss: 1.0622 - val_acc: 0.7288\n",
      "Epoch 793/800\n",
      "3200/3200 [==============================] - 1s 210us/step - loss: 1.2282 - acc: 0.6656 - val_loss: 1.0547 - val_acc: 0.7425\n",
      "Epoch 794/800\n",
      "3200/3200 [==============================] - 1s 188us/step - loss: 1.2195 - acc: 0.6628 - val_loss: 1.0329 - val_acc: 0.7362\n",
      "Epoch 795/800\n",
      "3200/3200 [==============================] - 1s 181us/step - loss: 1.2498 - acc: 0.6562 - val_loss: 1.0465 - val_acc: 0.7425\n",
      "Epoch 796/800\n",
      "3200/3200 [==============================] - 1s 216us/step - loss: 1.1995 - acc: 0.6716 - val_loss: 0.9976 - val_acc: 0.7550\n",
      "Epoch 797/800\n",
      "3200/3200 [==============================] - 1s 350us/step - loss: 1.2413 - acc: 0.6672 - val_loss: 1.0020 - val_acc: 0.7562\n",
      "Epoch 798/800\n",
      "3200/3200 [==============================] - 1s 237us/step - loss: 1.1958 - acc: 0.6803 - val_loss: 1.0279 - val_acc: 0.7500\n",
      "Epoch 799/800\n",
      "3200/3200 [==============================] - 1s 289us/step - loss: 1.2323 - acc: 0.6644 - val_loss: 1.0648 - val_acc: 0.7288\n",
      "Epoch 800/800\n",
      "3200/3200 [==============================] - 1s 285us/step - loss: 1.2831 - acc: 0.6538 - val_loss: 1.0051 - val_acc: 0.7375\n"
     ]
    }
   ],
   "source": [
    "#Train a model\n",
    "train(model,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = '50 classes classification model-3-layer-84ac'\n",
    "model =  load_model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 247us/step\n",
      "Accuracy :  84.0\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test,y_test)\n",
    "print(\"Accuracy : \", score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class :  6 hen\n",
      "Probability :  99.74905252456665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admins\\Anaconda3\\envs\\rnn-env\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Numeric-style type codes are deprecated and will result in an error in the future.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Admins\\Anaconda3\\envs\\rnn-env\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#predict 1 \n",
    "filename = 'E:/Dataset/ESC-50-master/audio/1-5996-A-6.wav'\n",
    "predict(filename,le,model,label,is_play_sound =False)\n",
    "visualize_wav(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/Dataset/ESC-50-master/audio/2-84965-A-23.wav\n",
      "Predicted class :  23 breathing\n",
      "Probability :  83.03165435791016\n",
      "E:/Dataset/ESC-50-master/audio/3-253084-A-2.wav\n",
      "Predicted class :  2 pig\n",
      "Probability :  99.98804330825806\n",
      "E:/Dataset/ESC-50-master/audio/2-76868-A-6.wav\n",
      "Predicted class :  6 hen\n",
      "Probability :  99.99955892562866\n",
      "E:/Dataset/ESC-50-master/audio/4-152958-A-18.wav\n",
      "Predicted class :  25 footsteps\n",
      "Probability :  68.28627586364746\n",
      "E:/Dataset/ESC-50-master/audio/4-208021-A-1.wav\n",
      "Predicted class :  23 breathing\n",
      "Probability :  24.462813138961792\n",
      "E:/Dataset/ESC-50-master/audio/3-103599-A-25.wav\n",
      "Predicted class :  25 footsteps\n",
      "Probability :  98.07523488998413\n",
      "E:/Dataset/ESC-50-master/audio/5-251963-A-47.wav\n",
      "Predicted class :  47 airplane\n",
      "Probability :  54.21851873397827\n",
      "E:/Dataset/ESC-50-master/audio/3-144891-B-19.wav\n",
      "Predicted class :  19 thunderstorm\n",
      "Probability :  67.36412048339844\n",
      "E:/Dataset/ESC-50-master/audio/3-174840-A-43.wav\n",
      "Predicted class :  43 car_horn\n",
      "Probability :  97.81128764152527\n",
      "E:/Dataset/ESC-50-master/audio/3-141684-A-21.wav\n",
      "Predicted class :  21 sneezing\n",
      "Probability :  44.85529363155365\n"
     ]
    }
   ],
   "source": [
    " #predict multiple \n",
    "predic_multiple(model,le,label,number = 10, path= 'E:/Dataset/ESC-50-master/audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'E:/Dataset/ESC-50-master/audio/2-70052-A-42.wav'\n",
    "visualize_wav(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_proba_vector = model.predict_proba(prediction_feature)\n",
    "predicted_proba = predicted_proba_vector[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
